{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task1: Predict total passenger flow volume for the next 5-minute time slice\n",
    "# Based on cleaned CSVs:\n",
    "# /mnt/data/hall_calls_clean.csv\n",
    "# /mnt/data/load_changes_clean.csv\n",
    "# /mnt/data/car_calls_clean.csv\n",
    "# /mnt/data/car_stops_clean.csv\n",
    "# /mnt/data/car_departures_clean.csv\n",
    "# /mnt/data/maintenance_mode_clean.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Paths\n",
    "# -----------------------------\n",
    "PATH_HALL = \"/mnt/data/hall_calls_clean.csv\"\n",
    "PATH_LOAD = \"/mnt/data/load_changes_clean.csv\"\n",
    "PATH_MAINT = \"/mnt/data/maintenance_mode_clean.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Config\n",
    "# -----------------------------\n",
    "FREQ = \"5min\"\n",
    "\n",
    "# 客流定义方式：\n",
    "# \"hall_calls\" = 每5分钟 hall call 数（推荐）\n",
    "# \"load_in\"    = 每5分钟 Load In 总重量 / avg_weight 估算人数（需要你确认单位与平均体重）\n",
    "FLOW_MODE = \"hall_calls\"\n",
    "\n",
    "# 仅在 FLOW_MODE=\"load_in\" 时使用：平均乘客体重（单位要与 Load In 一致）\n",
    "AVG_PASSENGER_WEIGHT = 65.0  # 例如 65 kg（如果 Load In 是 kg）；不确定请改成你们合理数值\n",
    "\n",
    "# 滞后特征：用过去多少个 5-min 片段\n",
    "LAGS = [1, 2, 3, 6, 12]  # 5/10/15/30/60分钟\n",
    "ROLL_WINDOWS = [3, 6, 12]  # rolling mean window size in slices\n",
    "\n",
    "# 训练集比例（按时间顺序切分）\n",
    "TRAIN_RATIO = 0.85\n",
    "\n",
    "MODEL_OUT = \"task1_flow_model.joblib\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Helpers\n",
    "# -----------------------------\n",
    "def add_time_features(df: pd.DataFrame, time_col=\"Time\") -> pd.DataFrame:\n",
    "    \"\"\"加入能适应一天不同时段的周期特征\"\"\"\n",
    "    out = df.copy()\n",
    "    t = out[time_col]\n",
    "\n",
    "    out[\"hour\"] = t.dt.hour\n",
    "    out[\"minute\"] = t.dt.minute\n",
    "    out[\"dow\"] = t.dt.dayofweek  # Monday=0\n",
    "\n",
    "    # 一天的分钟数 [0, 1440)\n",
    "    minute_of_day = out[\"hour\"] * 60 + out[\"minute\"]\n",
    "    # 周期编码：sin/cos（适应昼夜规律）\n",
    "    out[\"sin_day\"] = np.sin(2 * np.pi * minute_of_day / 1440.0)\n",
    "    out[\"cos_day\"] = np.cos(2 * np.pi * minute_of_day / 1440.0)\n",
    "\n",
    "    # 一周周期（可选）\n",
    "    out[\"sin_week\"] = np.sin(2 * np.pi * out[\"dow\"] / 7.0)\n",
    "    out[\"cos_week\"] = np.cos(2 * np.pi * out[\"dow\"] / 7.0)\n",
    "\n",
    "    # 是否工作日\n",
    "    out[\"is_weekend\"] = (out[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_lag_features(df: pd.DataFrame, y_col=\"y\") -> pd.DataFrame:\n",
    "    \"\"\"滞后 + 滚动统计特征\"\"\"\n",
    "    out = df.copy()\n",
    "    for lag in LAGS:\n",
    "        out[f\"lag_{lag}\"] = out[y_col].shift(lag)\n",
    "\n",
    "    for w in ROLL_WINDOWS:\n",
    "        out[f\"roll_mean_{w}\"] = out[y_col].shift(1).rolling(w).mean()\n",
    "        out[f\"roll_std_{w}\"] = out[y_col].shift(1).rolling(w).std()\n",
    "\n",
    "    # 简单趋势：最近1小时与前1小时差（如果有足够数据）\n",
    "    if 12 in LAGS:\n",
    "        out[\"trend_1h\"] = out[\"lag_1\"] - out[\"lag_12\"]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_flow_series(freq=FREQ, mode=FLOW_MODE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    构造 5分钟总客流时间序列。\n",
    "    mode:\n",
    "      - hall_calls: 每5min hall_calls数量\n",
    "      - load_in: 每5min Load In/avg_weight 估算“进电梯人数”\n",
    "    \"\"\"\n",
    "    if mode == \"hall_calls\":\n",
    "        hall = pd.read_csv(PATH_HALL)\n",
    "        hall[\"Time\"] = pd.to_datetime(hall[\"Time\"])\n",
    "        # 5分钟聚合：数量\n",
    "        s = hall.set_index(\"Time\").resample(freq).size().rename(\"y\").to_frame()\n",
    "\n",
    "    elif mode == \"load_in\":\n",
    "        load = pd.read_csv(PATH_LOAD)\n",
    "        load[\"Time\"] = pd.to_datetime(load[\"Time\"])\n",
    "        # 5分钟聚合：Load In 总重量 -> 估计人数\n",
    "        s = load.set_index(\"Time\")[\"Load In\"].resample(freq).sum().fillna(0)\n",
    "        s = (s / AVG_PASSENGER_WEIGHT).rename(\"y\").to_frame()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"FLOW_MODE must be 'hall_calls' or 'load_in'\")\n",
    "\n",
    "    # 补齐缺失时间片\n",
    "    s = s.asfreq(freq, fill_value=0).reset_index().rename(columns={\"Time\": \"Time\"})\n",
    "    return s\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Train + Evaluate + Predict\n",
    "# -----------------------------\n",
    "def train_task1():\n",
    "    # 3.1 Build target series\n",
    "    df = build_flow_series()\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "\n",
    "    # 3.2 Add features\n",
    "    df = add_time_features(df, \"Time\")\n",
    "    df = add_lag_features(df, \"y\")\n",
    "\n",
    "    # 3.3 Drop rows with NaNs due to lag/rolling\n",
    "    df_feat = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    feature_cols = [\n",
    "        \"sin_day\", \"cos_day\", \"sin_week\", \"cos_week\", \"is_weekend\",\n",
    "        \"hour\", \"minute\",\n",
    "    ] + [f\"lag_{l}\" for l in LAGS] + \\\n",
    "        [f\"roll_mean_{w}\" for w in ROLL_WINDOWS] + \\\n",
    "        [f\"roll_std_{w}\" for w in ROLL_WINDOWS] + ([\"trend_1h\"] if \"trend_1h\" in df_feat.columns else [])\n",
    "\n",
    "    X = df_feat[feature_cols].values\n",
    "    y = df_feat[\"y\"].values\n",
    "\n",
    "    # 3.4 Time-based split\n",
    "    n = len(df_feat)\n",
    "    n_train = int(n * TRAIN_RATIO)\n",
    "\n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_test, y_test = X[n_train:], y[n_train:]\n",
    "\n",
    "    # 3.5 Model\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        loss=\"squared_error\",\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        max_iter=400,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 3.6 Evaluate\n",
    "    pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "\n",
    "    print(\"========== Task1 Result ==========\")\n",
    "    print(f\"FLOW_MODE = {FLOW_MODE}\")\n",
    "    print(f\"Test MAE  = {mae:.4f}\")\n",
    "    print(f\"Test RMSE = {rmse:.4f}\")\n",
    "\n",
    "    # 3.7 Save\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"feature_cols\": feature_cols,\n",
    "        \"freq\": FREQ,\n",
    "        \"flow_mode\": FLOW_MODE,\n",
    "        \"avg_passenger_weight\": AVG_PASSENGER_WEIGHT,\n",
    "        \"lags\": LAGS,\n",
    "        \"roll_windows\": ROLL_WINDOWS\n",
    "    }\n",
    "    joblib.dump(payload, MODEL_OUT)\n",
    "    print(f\"Saved model to: {MODEL_OUT}\")\n",
    "\n",
    "    # 3.8 Predict next 5-min slice using the latest available time slice\n",
    "    next_pred, next_time = predict_next(df, payload)\n",
    "    print(f\"Next slice time: {next_time}\")\n",
    "    print(f\"Predicted flow : {next_pred:.4f}\")\n",
    "\n",
    "    return payload\n",
    "\n",
    "\n",
    "def predict_next(raw_df: pd.DataFrame, payload: dict):\n",
    "    \"\"\"\n",
    "    raw_df: dataframe with columns [Time, y] at 5min freq (may include other cols)\n",
    "    \"\"\"\n",
    "    model = payload[\"model\"]\n",
    "    feature_cols = payload[\"feature_cols\"]\n",
    "\n",
    "    df = raw_df.copy()\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "\n",
    "    # Rebuild features the same way\n",
    "    df = add_time_features(df, \"Time\")\n",
    "    df = add_lag_features(df, \"y\")\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Take last row as \"current time slice\", then we predict next one by creating next time row\n",
    "    last = df.iloc[-1:].copy()\n",
    "    last_time = last[\"Time\"].iloc[0]\n",
    "    next_time = last_time + pd.Timedelta(FREQ)\n",
    "\n",
    "    # Create a new row for next_time with y unknown, but lag features come from history\n",
    "    next_row = pd.DataFrame({\"Time\": [next_time], \"y\": [np.nan]})\n",
    "    next_row = add_time_features(next_row, \"Time\")\n",
    "\n",
    "    # Build lag/rolling features for next time based on existing y series\n",
    "    y_series = df.set_index(\"Time\")[\"y\"].copy()\n",
    "\n",
    "    # Fill lag features\n",
    "    for lag in LAGS:\n",
    "        next_row[f\"lag_{lag}\"] = y_series.iloc[-lag] if len(y_series) >= lag else np.nan\n",
    "\n",
    "    # Fill rolling features\n",
    "    for w in ROLL_WINDOWS:\n",
    "        vals = y_series.iloc[-w:] if len(y_series) >= w else y_series\n",
    "        next_row[f\"roll_mean_{w}\"] = vals.mean() if len(vals) > 0 else np.nan\n",
    "        next_row[f\"roll_std_{w}\"] = vals.std() if len(vals) > 1 else 0.0\n",
    "\n",
    "    if \"trend_1h\" in feature_cols:\n",
    "        if len(y_series) >= 12:\n",
    "            next_row[\"trend_1h\"] = y_series.iloc[-1] - y_series.iloc[-12]\n",
    "        else:\n",
    "            next_row[\"trend_1h\"] = 0.0\n",
    "\n",
    "    # Ensure all required features exist\n",
    "    for c in feature_cols:\n",
    "        if c not in next_row.columns:\n",
    "            next_row[c] = 0.0\n",
    "\n",
    "    X_next = next_row[feature_cols].values\n",
    "    pred_next = model.predict(X_next)[0]\n",
    "    return float(pred_next), str(next_time)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_task1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5224e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task2: Automatically classify current building traffic state (\"modes\") using real-time features\n",
    "# Based on cleaned CSVs:\n",
    "# /mnt/data/hall_calls_clean.csv\n",
    "# /mnt/data/load_changes_clean.csv\n",
    "# /mnt/data/car_calls_clean.csv\n",
    "# /mnt/data/car_stops_clean.csv\n",
    "# /mnt/data/car_departures_clean.csv\n",
    "# /mnt/data/maintenance_mode_clean.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Paths\n",
    "# -----------------------------\n",
    "PATH_HALL = \"/mnt/data/hall_calls_clean.csv\"\n",
    "PATH_CAR_CALL = \"/mnt/data/car_calls_clean.csv\"\n",
    "PATH_CAR_STOP = \"/mnt/data/car_stops_clean.csv\"\n",
    "PATH_CAR_DEP = \"/mnt/data/car_departures_clean.csv\"\n",
    "PATH_LOAD = \"/mnt/data/load_changes_clean.csv\"\n",
    "PATH_MAINT = \"/mnt/data/maintenance_mode_clean.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Config\n",
    "# -----------------------------\n",
    "FREQ = \"5min\"          # base slice\n",
    "WINDOW = \"15min\"       # \"real-time\" window to smooth (rolling)\n",
    "N_CLUSTERS = 6         # you can tune 5~8\n",
    "MODEL_OUT = \"task2_mode_model.joblib\"\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Robust column helpers\n",
    "# -----------------------------\n",
    "def pick_col(df, candidates, required=False):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    if required:\n",
    "        raise KeyError(f\"None of these columns exist: {candidates}\")\n",
    "    return None\n",
    "\n",
    "def normalize_direction(series):\n",
    "    \"\"\"\n",
    "    Convert direction to +1 (Up), -1 (Down), 0 (Unknown).\n",
    "    Accepts strings like 'Up','Down','U','D', 1/-1, etc.\n",
    "    \"\"\"\n",
    "    s = series.copy()\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        # assume up>0, down<0, else 0\n",
    "        out = np.where(s > 0, 1, np.where(s < 0, -1, 0))\n",
    "        return pd.Series(out, index=s.index)\n",
    "\n",
    "    ss = s.astype(str).str.lower()\n",
    "    up = ss.str.contains(\"up\") | ss.str.fullmatch(\"u\") | ss.str.contains(\"↑\")\n",
    "    down = ss.str.contains(\"down\") | ss.str.fullmatch(\"d\") | ss.str.contains(\"↓\")\n",
    "    out = np.where(up, 1, np.where(down, -1, 0))\n",
    "    return pd.Series(out, index=s.index)\n",
    "\n",
    "def floor_entropy(values):\n",
    "    \"\"\"Normalized entropy of floor distribution (0~1).\"\"\"\n",
    "    v = pd.Series(values).dropna()\n",
    "    if len(v) == 0:\n",
    "        return 0.0\n",
    "    counts = v.value_counts()\n",
    "    p = counts / counts.sum()\n",
    "    ent = -(p * np.log(p + 1e-12)).sum()\n",
    "    ent_norm = ent / (np.log(len(counts) + 1e-12))\n",
    "    return float(ent_norm)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Load data\n",
    "# -----------------------------\n",
    "def load_all():\n",
    "    hall = pd.read_csv(PATH_HALL)\n",
    "    car_call = pd.read_csv(PATH_CAR_CALL)\n",
    "    car_stop = pd.read_csv(PATH_CAR_STOP)\n",
    "    car_dep = pd.read_csv(PATH_CAR_DEP)\n",
    "    load = pd.read_csv(PATH_LOAD)\n",
    "    maint = pd.read_csv(PATH_MAINT)\n",
    "\n",
    "    # parse time\n",
    "    for df in [hall, car_call, car_stop, car_dep, load, maint]:\n",
    "        tcol = pick_col(df, [\"Time\", \"time\", \"timestamp\", \"Datetime\", \"DateTime\"], required=True)\n",
    "        df[\"Time\"] = pd.to_datetime(df[tcol])\n",
    "    return hall, car_call, car_stop, car_dep, load, maint\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Build 5-min base features\n",
    "# -----------------------------\n",
    "def build_base_features(freq=FREQ):\n",
    "    hall, car_call, car_stop, car_dep, load, maint = load_all()\n",
    "\n",
    "    # --- Hall call features ---\n",
    "    hall_dir_col = pick_col(hall, [\"Direction\", \"direction\", \"CallDirection\", \"HallDirection\", \"UpDown\", \"dir\"])\n",
    "    hall_floor_col = pick_col(hall, [\"Floor\", \"floor\", \"OriginFloor\", \"FromFloor\", \"HallFloor\", \"StartFloor\"])\n",
    "\n",
    "    hall_idx = hall.set_index(\"Time\")\n",
    "\n",
    "    hall_count = hall_idx.resample(freq).size().rename(\"hall_calls\")\n",
    "\n",
    "    if hall_dir_col:\n",
    "        d = normalize_direction(hall_idx[hall_dir_col])\n",
    "        up = (d == 1).resample(freq).sum().rename(\"hall_up\")\n",
    "        down = (d == -1).resample(freq).sum().rename(\"hall_down\")\n",
    "    else:\n",
    "        up = pd.Series(dtype=float, name=\"hall_up\")\n",
    "        down = pd.Series(dtype=float, name=\"hall_down\")\n",
    "\n",
    "    # entropy of origin floors per slice\n",
    "    if hall_floor_col:\n",
    "        hall_entropy = hall_idx[hall_floor_col].resample(freq).apply(floor_entropy).rename(\"hall_origin_entropy\")\n",
    "    else:\n",
    "        hall_entropy = pd.Series(index=hall_count.index, data=0.0, name=\"hall_origin_entropy\")\n",
    "\n",
    "    # --- Car call features (optional, inter-floor indicator) ---\n",
    "    car_from_col = pick_col(car_call, [\"FromFloor\", \"from_floor\", \"OriginFloor\", \"StartFloor\", \"Floor\"])\n",
    "    car_to_col = pick_col(car_call, [\"ToFloor\", \"to_floor\", \"DestinationFloor\", \"DestFloor\", \"TargetFloor\"])\n",
    "    car_idx = car_call.set_index(\"Time\")\n",
    "\n",
    "    car_calls = car_idx.resample(freq).size().rename(\"car_calls\")\n",
    "\n",
    "    # fraction of \"inter-floor\" (from != 1 and to != 1) — if floors exist\n",
    "    if car_from_col and car_to_col:\n",
    "        fromf = car_idx[car_from_col]\n",
    "        tof = car_idx[car_to_col]\n",
    "        inter = ((fromf != 1) & (tof != 1) & (fromf.notna()) & (tof.notna()))\n",
    "        inter_ratio = inter.resample(freq).mean().rename(\"car_inter_ratio\")\n",
    "    else:\n",
    "        inter_ratio = pd.Series(index=car_calls.index, data=0.0, name=\"car_inter_ratio\")\n",
    "\n",
    "    # --- Car stops (stop intensity) ---\n",
    "    stop_reason_col = pick_col(car_stop, [\"Reason\", \"reason\", \"StopReason\"])\n",
    "    stop_dir_col = pick_col(car_stop, [\"Direction\", \"direction\", \"Dir\", \"UpDown\", \"dir\"])\n",
    "    stop_idx = car_stop.set_index(\"Time\")\n",
    "\n",
    "    stops = stop_idx.resample(freq).size().rename(\"car_stops\")\n",
    "\n",
    "    if stop_dir_col:\n",
    "        sd = normalize_direction(stop_idx[stop_dir_col])\n",
    "        stops_up = (sd == 1).resample(freq).sum().rename(\"stops_up\")\n",
    "        stops_down = (sd == -1).resample(freq).sum().rename(\"stops_down\")\n",
    "    else:\n",
    "        stops_up = pd.Series(dtype=float, name=\"stops_up\")\n",
    "        stops_down = pd.Series(dtype=float, name=\"stops_down\")\n",
    "\n",
    "    # --- Departures (service activity) ---\n",
    "    dep_idx = car_dep.set_index(\"Time\")\n",
    "    deps = dep_idx.resample(freq).size().rename(\"departures\")\n",
    "\n",
    "    # --- Load changes (proxy for passenger movement) ---\n",
    "    load_idx = load.set_index(\"Time\")\n",
    "    load_in_col = pick_col(load, [\"Load In\", \"LoadIn\", \"load_in\", \"InLoad\", \"WeightIn\"])\n",
    "    load_out_col = pick_col(load, [\"Load Out\", \"LoadOut\", \"load_out\", \"OutLoad\", \"WeightOut\"])\n",
    "\n",
    "    if load_in_col:\n",
    "        load_in = load_idx[load_in_col].resample(freq).sum().fillna(0).rename(\"load_in_sum\")\n",
    "    else:\n",
    "        load_in = pd.Series(index=hall_count.index, data=0.0, name=\"load_in_sum\")\n",
    "\n",
    "    if load_out_col:\n",
    "        load_out = load_idx[load_out_col].resample(freq).sum().fillna(0).rename(\"load_out_sum\")\n",
    "    else:\n",
    "        load_out = pd.Series(index=hall_count.index, data=0.0, name=\"load_out_sum\")\n",
    "\n",
    "    # --- Maintenance (exclude or feature) ---\n",
    "    maint_idx = maint.set_index(\"Time\")\n",
    "    maint_col = pick_col(maint, [\"Maintenance\", \"maintenance\", \"IsMaintenance\", \"MaintMode\", \"Mode\"], required=False)\n",
    "    elev_col = pick_col(maint, [\"Elevator\", \"elevator\", \"CarID\", \"CarId\", \"LiftID\", \"ID\"], required=False)\n",
    "\n",
    "    # maintenance ratio per slice: % elevators in maintenance\n",
    "    if maint_col and elev_col:\n",
    "        # Expect records indicating current status; we'll treat each row as a status sample\n",
    "        m = maint_idx.copy()\n",
    "        m[\"maint_flag\"] = m[maint_col].astype(int) if pd.api.types.is_numeric_dtype(m[maint_col]) else (m[maint_col].astype(str).str.lower().isin([\"1\",\"true\",\"yes\",\"maint\",\"maintenance\"])).astype(int)\n",
    "        # within each slice, compute mean over elevators (approx)\n",
    "        maint_ratio = m.groupby([pd.Grouper(freq=freq), elev_col])[\"maint_flag\"].last().groupby(level=0).mean()\n",
    "        maint_ratio = maint_ratio.reindex(hall_count.index).fillna(method=\"ffill\").fillna(0).rename(\"maint_ratio\")\n",
    "    else:\n",
    "        maint_ratio = pd.Series(index=hall_count.index, data=0.0, name=\"maint_ratio\")\n",
    "\n",
    "    # --- Merge all ---\n",
    "    feats = pd.concat([\n",
    "        hall_count,\n",
    "        up.reindex(hall_count.index).fillna(0).rename(\"hall_up\"),\n",
    "        down.reindex(hall_count.index).fillna(0).rename(\"hall_down\"),\n",
    "        hall_entropy.reindex(hall_count.index).fillna(0),\n",
    "        car_calls.reindex(hall_count.index).fillna(0),\n",
    "        inter_ratio.reindex(hall_count.index).fillna(0),\n",
    "        stops.reindex(hall_count.index).fillna(0),\n",
    "        stops_up.reindex(hall_count.index).fillna(0),\n",
    "        stops_down.reindex(hall_count.index).fillna(0),\n",
    "        deps.reindex(hall_count.index).fillna(0),\n",
    "        load_in.reindex(hall_count.index).fillna(0),\n",
    "        load_out.reindex(hall_count.index).fillna(0),\n",
    "        maint_ratio.reindex(hall_count.index).fillna(0),\n",
    "    ], axis=1)\n",
    "\n",
    "    feats.index.name = \"Time\"\n",
    "\n",
    "    # derived ratios\n",
    "    total = feats[\"hall_calls\"].replace(0, np.nan)\n",
    "    feats[\"up_ratio\"] = (feats[\"hall_up\"] / total).fillna(0)\n",
    "    feats[\"down_ratio\"] = (feats[\"hall_down\"] / total).fillna(0)\n",
    "\n",
    "    # activity score (simple)\n",
    "    feats[\"activity\"] = (\n",
    "        feats[\"hall_calls\"]\n",
    "        + 0.3 * feats[\"car_calls\"]\n",
    "        + 0.5 * feats[\"car_stops\"]\n",
    "        + 0.2 * feats[\"departures\"]\n",
    "    )\n",
    "\n",
    "    # net load (optional)\n",
    "    feats[\"net_load\"] = feats[\"load_in_sum\"] - feats[\"load_out_sum\"]\n",
    "\n",
    "    # time features\n",
    "    t = feats.index\n",
    "    feats[\"hour\"] = t.hour\n",
    "    feats[\"dow\"] = t.dayofweek\n",
    "    minute_of_day = t.hour * 60 + t.minute\n",
    "    feats[\"sin_day\"] = np.sin(2 * np.pi * minute_of_day / 1440.0)\n",
    "    feats[\"cos_day\"] = np.cos(2 * np.pi * minute_of_day / 1440.0)\n",
    "\n",
    "    return feats.reset_index()\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Rolling window smoothing (real-time features)\n",
    "# -----------------------------\n",
    "def add_realtime_window(df, freq=FREQ, window=WINDOW):\n",
    "    df = df.sort_values(\"Time\").copy()\n",
    "    df = df.set_index(\"Time\")\n",
    "\n",
    "    # choose numeric columns to smooth\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    # rolling mean over window\n",
    "    roll = df[num_cols].rolling(window=window, min_periods=1).mean()\n",
    "    roll.columns = [f\"{c}_w\" for c in roll.columns]\n",
    "\n",
    "    out = pd.concat([df, roll], axis=1).reset_index()\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Cluster -> mode naming (interpretable)\n",
    "# -----------------------------\n",
    "def name_modes(cluster_summary: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Given per-cluster mean features, return mapping cluster -> human-readable label.\n",
    "    Uses rule-based interpretation:\n",
    "      - Up-Peak: high activity + up_ratio high\n",
    "      - Down-Peak: high activity + down_ratio high\n",
    "      - Inter-floor: high car_inter_ratio + hall_origin_entropy high (more distributed)\n",
    "      - Idle/Low: low activity\n",
    "      - Balanced: medium activity, up/down balanced\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    # pick some columns (windowed preferred if available)\n",
    "    def c(name):\n",
    "        return name if name in cluster_summary.columns else f\"{name}_w\"\n",
    "\n",
    "    for _, row in cluster_summary.iterrows():\n",
    "        k = int(row[\"cluster\"])\n",
    "        activity = row[c(\"activity\")]\n",
    "        up = row[c(\"up_ratio\")]\n",
    "        down = row[c(\"down_ratio\")]\n",
    "        inter = row[c(\"car_inter_ratio\")]\n",
    "        ent = row[c(\"hall_origin_entropy\")]\n",
    "\n",
    "        if activity < cluster_summary[c(\"activity\")].quantile(0.25):\n",
    "            label = \"Idle/Low\"\n",
    "        elif up > 0.65 and activity >= cluster_summary[c(\"activity\")].median():\n",
    "            label = \"Morning Up-Peak\"\n",
    "        elif down > 0.65 and activity >= cluster_summary[c(\"activity\")].median():\n",
    "            label = \"Evening Down-Peak\"\n",
    "        elif inter > 0.45 or ent > 0.70:\n",
    "            label = \"Meeting/Inter-floor\"\n",
    "        else:\n",
    "            label = \"Balanced/Meal-hour\"\n",
    "\n",
    "        mapping[k] = label\n",
    "    return mapping\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Train Task2 model\n",
    "# -----------------------------\n",
    "def train_task2():\n",
    "    base = build_base_features()\n",
    "    feat = add_realtime_window(base)\n",
    "\n",
    "    # Use windowed features as \"real-time\" signals\n",
    "    feature_cols = [\n",
    "        \"hall_calls_w\",\n",
    "        \"up_ratio_w\",\n",
    "        \"down_ratio_w\",\n",
    "        \"hall_origin_entropy_w\",\n",
    "        \"car_calls_w\",\n",
    "        \"car_inter_ratio_w\",\n",
    "        \"car_stops_w\",\n",
    "        \"departures_w\",\n",
    "        \"load_in_sum_w\",\n",
    "        \"load_out_sum_w\",\n",
    "        \"net_load_w\",\n",
    "        \"maint_ratio_w\",\n",
    "        \"sin_day\", \"cos_day\"\n",
    "    ]\n",
    "\n",
    "    # Ensure missing columns exist (if some sources lack fields)\n",
    "    for c in feature_cols:\n",
    "        if c not in feat.columns:\n",
    "            feat[c] = 0.0\n",
    "\n",
    "    X = feat[feature_cols].fillna(0.0).values\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"kmeans\", KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=20))\n",
    "    ])\n",
    "    pipe.fit(X)\n",
    "\n",
    "    clusters = pipe.predict(X)\n",
    "    feat[\"cluster\"] = clusters\n",
    "\n",
    "    # silhouette (rough cluster quality)\n",
    "    if len(np.unique(clusters)) > 1:\n",
    "        sil = silhouette_score(StandardScaler().fit_transform(X), clusters)\n",
    "        print(f\"Silhouette score: {sil:.4f}\")\n",
    "    else:\n",
    "        print(\"Silhouette score: N/A (only one cluster)\")\n",
    "\n",
    "    # cluster summary\n",
    "    summary = feat.groupby(\"cluster\")[feature_cols].mean().reset_index()\n",
    "    mapping = name_modes(summary)\n",
    "\n",
    "    feat[\"mode_label\"] = feat[\"cluster\"].map(mapping)\n",
    "\n",
    "    # Save model + config\n",
    "    payload = {\n",
    "        \"pipeline\": pipe,\n",
    "        \"feature_cols\": feature_cols,\n",
    "        \"freq\": FREQ,\n",
    "        \"window\": WINDOW,\n",
    "        \"n_clusters\": N_CLUSTERS,\n",
    "        \"cluster_to_mode\": mapping\n",
    "    }\n",
    "    joblib.dump(payload, MODEL_OUT)\n",
    "    print(f\"Saved Task2 model to: {MODEL_OUT}\")\n",
    "\n",
    "    # show distribution\n",
    "    print(\"\\nMode counts:\")\n",
    "    print(feat[\"mode_label\"].value_counts())\n",
    "\n",
    "    # example: current mode (latest time slice)\n",
    "    current = feat.iloc[-1]\n",
    "    print(\"\\nCurrent Time:\", current[\"Time\"])\n",
    "    print(\"Current Cluster:\", int(current[\"cluster\"]))\n",
    "    print(\"Current Mode:\", current[\"mode_label\"])\n",
    "\n",
    "    # output a csv for report figures\n",
    "    out_csv = \"task2_modes_timeline.csv\"\n",
    "    feat[[\"Time\", \"cluster\", \"mode_label\"] + feature_cols].to_csv(out_csv, index=False)\n",
    "    print(f\"Saved timeline to: {out_csv}\")\n",
    "\n",
    "    return feat, payload\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Real-time classify function\n",
    "# -----------------------------\n",
    "def classify_current_state(latest_rows_df: pd.DataFrame, payload_path=MODEL_OUT):\n",
    "    \"\"\"\n",
    "    If later you stream data, you can pass in a DataFrame with the same columns as base features,\n",
    "    then compute window features and predict current mode.\n",
    "    For now, use the saved model.\n",
    "    \"\"\"\n",
    "    payload = joblib.load(payload_path)\n",
    "    pipe = payload[\"pipeline\"]\n",
    "    feature_cols = payload[\"feature_cols\"]\n",
    "    mapping = payload[\"cluster_to_mode\"]\n",
    "\n",
    "    # expects latest_rows_df already has windowed columns or you can build similarly\n",
    "    df = latest_rows_df.copy()\n",
    "    for c in feature_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0.0\n",
    "    X = df[feature_cols].fillna(0.0).values\n",
    "    cl = int(pipe.predict(X)[-1])\n",
    "    return cl, mapping.get(cl, \"Unknown\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_task2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task3: Dynamic Parking Strategy Model (with a lightweight, reproducible simulator)\n",
    "# ------------------------------------------------------------\n",
    "# Uses your cleaned logs to:\n",
    "# 1) Learn demand-by-floor patterns conditioned on \"building mode\" (from Task2-style features)\n",
    "# 2) Build a Dynamic Parking Policy (k-median on floors with predicted demand weights)\n",
    "# 3) Simulate and compare 3 strategies:\n",
    "#    - \"last_stop\": do nothing (idle stays where it is)\n",
    "#    - \"lobby\": send idle elevators to lobby (floor=1)\n",
    "#    - \"dynamic\": mode-aware k-median parking floors + assignment\n",
    "#\n",
    "# Outputs:\n",
    "# - Average Waiting Time (AWT) and % Long Waits (>=60s) for each strategy\n",
    "#\n",
    "# Files used (cleaned CSV):\n",
    "# /mnt/data/hall_calls_clean.csv\n",
    "# /mnt/data/car_stops_clean.csv\n",
    "# /mnt/data/car_departures_clean.csv\n",
    "# /mnt/data/load_changes_clean.csv\n",
    "# /mnt/data/maintenance_mode_clean.csv\n",
    "# /mnt/data/car_calls_clean.csv  (optional here; not needed for basic simulation)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "PATH_HALL = \"/mnt/data/hall_calls_clean.csv\"\n",
    "PATH_STOP = \"/mnt/data/car_stops_clean.csv\"\n",
    "PATH_DEP  = \"/mnt/data/car_departures_clean.csv\"\n",
    "PATH_LOAD = \"/mnt/data/load_changes_clean.csv\"\n",
    "PATH_MAINT= \"/mnt/data/maintenance_mode_clean.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# Config (tune if you want)\n",
    "# -----------------------------\n",
    "N_ELEVATORS = 8\n",
    "LOBBY_FLOOR = 1\n",
    "\n",
    "# \"Realistic-ish\" travel parameters (you can tune)\n",
    "SECONDS_PER_FLOOR = 1.5     # travel time per floor\n",
    "DOOR_TIME = 8.0             # open + dwell + close\n",
    "LONG_WAIT_THRESHOLD = 60.0  # seconds\n",
    "\n",
    "# Parking decision cadence / prediction horizon\n",
    "DECISION_FREQ = \"5min\"\n",
    "PRED_HORIZON_MIN = 15       # demand for next 15 minutes to choose parking\n",
    "\n",
    "# Cluster count for \"mode\" discovery\n",
    "N_CLUSTERS = 6\n",
    "\n",
    "# -----------------------------\n",
    "# Robust column pickers\n",
    "# -----------------------------\n",
    "def pick_col(df, candidates, required=False):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Missing required column. Tried: {candidates}\")\n",
    "    return None\n",
    "\n",
    "def normalize_direction(series):\n",
    "    \"\"\"Return +1 (Up), -1 (Down), 0 (Unknown).\"\"\"\n",
    "    s = series\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return pd.Series(np.where(s > 0, 1, np.where(s < 0, -1, 0)), index=s.index)\n",
    "    ss = s.astype(str).str.lower()\n",
    "    up = ss.str.contains(\"up\") | ss.str.fullmatch(\"u\") | ss.str.contains(\"↑\")\n",
    "    down = ss.str.contains(\"down\") | ss.str.fullmatch(\"d\") | ss.str.contains(\"↓\")\n",
    "    return pd.Series(np.where(up, 1, np.where(down, -1, 0)), index=s.index)\n",
    "\n",
    "def floor_entropy(values):\n",
    "    v = pd.Series(values).dropna()\n",
    "    if len(v) == 0:\n",
    "        return 0.0\n",
    "    counts = v.value_counts()\n",
    "    p = counts / counts.sum()\n",
    "    ent = -(p * np.log(p + 1e-12)).sum()\n",
    "    return float(ent / (np.log(len(counts) + 1e-12)))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load + standardize times\n",
    "# -----------------------------\n",
    "def load_data():\n",
    "    hall = pd.read_csv(PATH_HALL)\n",
    "    stop = pd.read_csv(PATH_STOP)\n",
    "    dep  = pd.read_csv(PATH_DEP)\n",
    "    load = pd.read_csv(PATH_LOAD)\n",
    "    maint= pd.read_csv(PATH_MAINT)\n",
    "\n",
    "    for df in [hall, stop, dep, load, maint]:\n",
    "        tcol = pick_col(df, [\"Time\", \"time\", \"timestamp\", \"Datetime\", \"DateTime\"], required=True)\n",
    "        df[\"Time\"] = pd.to_datetime(df[tcol])\n",
    "\n",
    "    return hall, stop, dep, load, maint\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build 5-min features (Task2-style) for mode clustering\n",
    "# -----------------------------\n",
    "def build_5min_features(freq=DECISION_FREQ):\n",
    "    hall, stop, dep, load, maint = load_data()\n",
    "\n",
    "    # Hall calls\n",
    "    h_dir = pick_col(hall, [\"Direction\",\"direction\",\"CallDirection\",\"HallDirection\",\"UpDown\",\"dir\"])\n",
    "    h_floor = pick_col(hall, [\"Floor\",\"floor\",\"OriginFloor\",\"FromFloor\",\"HallFloor\",\"StartFloor\"], required=True)\n",
    "    h = hall.set_index(\"Time\")\n",
    "\n",
    "    hall_calls = h.resample(freq).size().rename(\"hall_calls\")\n",
    "    if h_dir:\n",
    "        d = normalize_direction(h[h_dir])\n",
    "        hall_up = (d == 1).resample(freq).sum().rename(\"hall_up\")\n",
    "        hall_down = (d == -1).resample(freq).sum().rename(\"hall_down\")\n",
    "    else:\n",
    "        hall_up = pd.Series(index=hall_calls.index, data=0.0, name=\"hall_up\")\n",
    "        hall_down = pd.Series(index=hall_calls.index, data=0.0, name=\"hall_down\")\n",
    "\n",
    "    hall_ent = h[h_floor].resample(freq).apply(floor_entropy).rename(\"origin_entropy\")\n",
    "\n",
    "    # Stops\n",
    "    s = stop.set_index(\"Time\")\n",
    "    s_floor = pick_col(stop, [\"Floor\",\"floor\",\"StopFloor\",\"AtFloor\",\"CurrentFloor\"])\n",
    "    stops = s.resample(freq).size().rename(\"stops\")\n",
    "    if s_floor:\n",
    "        # \"stop entropy\" can proxy spread of served floors\n",
    "        stop_ent = s[s_floor].resample(freq).apply(floor_entropy).rename(\"stop_entropy\")\n",
    "    else:\n",
    "        stop_ent = pd.Series(index=hall_calls.index, data=0.0, name=\"stop_entropy\")\n",
    "\n",
    "    # Departures\n",
    "    d = dep.set_index(\"Time\")\n",
    "    departures = d.resample(freq).size().rename(\"departures\")\n",
    "\n",
    "    # Load changes\n",
    "    ld = load.set_index(\"Time\")\n",
    "    in_col = pick_col(load, [\"Load In\",\"LoadIn\",\"load_in\",\"InLoad\",\"WeightIn\"])\n",
    "    out_col= pick_col(load, [\"Load Out\",\"LoadOut\",\"load_out\",\"OutLoad\",\"WeightOut\"])\n",
    "    load_in = ld[in_col].resample(freq).sum().fillna(0).rename(\"load_in\") if in_col else pd.Series(index=hall_calls.index, data=0.0, name=\"load_in\")\n",
    "    load_out= ld[out_col].resample(freq).sum().fillna(0).rename(\"load_out\") if out_col else pd.Series(index=hall_calls.index, data=0.0, name=\"load_out\")\n",
    "\n",
    "    # Maintenance ratio (rough)\n",
    "    m = maint.set_index(\"Time\")\n",
    "    m_flag = pick_col(maint, [\"Maintenance\",\"maintenance\",\"IsMaintenance\",\"MaintMode\",\"Mode\"])\n",
    "    m_eid  = pick_col(maint, [\"Elevator\",\"elevator\",\"CarID\",\"CarId\",\"LiftID\",\"ID\"])\n",
    "    if m_flag and m_eid:\n",
    "        mm = m.copy()\n",
    "        mm[\"maint_flag\"] = (\n",
    "            mm[m_flag].astype(int) if pd.api.types.is_numeric_dtype(mm[m_flag])\n",
    "            else mm[m_flag].astype(str).str.lower().isin([\"1\",\"true\",\"yes\",\"maint\",\"maintenance\"]).astype(int)\n",
    "        )\n",
    "        maint_ratio = (\n",
    "            mm.groupby([pd.Grouper(freq=freq), m_eid])[\"maint_flag\"].last()\n",
    "              .groupby(level=0).mean()\n",
    "              .reindex(hall_calls.index).fillna(method=\"ffill\").fillna(0)\n",
    "              .rename(\"maint_ratio\")\n",
    "        )\n",
    "    else:\n",
    "        maint_ratio = pd.Series(index=hall_calls.index, data=0.0, name=\"maint_ratio\")\n",
    "\n",
    "    feats = pd.concat(\n",
    "        [\n",
    "            hall_calls,\n",
    "            hall_up.reindex(hall_calls.index).fillna(0),\n",
    "            hall_down.reindex(hall_calls.index).fillna(0),\n",
    "            hall_ent.reindex(hall_calls.index).fillna(0),\n",
    "            stops.reindex(hall_calls.index).fillna(0),\n",
    "            stop_ent.reindex(hall_calls.index).fillna(0),\n",
    "            departures.reindex(hall_calls.index).fillna(0),\n",
    "            load_in.reindex(hall_calls.index).fillna(0),\n",
    "            load_out.reindex(hall_calls.index).fillna(0),\n",
    "            maint_ratio.reindex(hall_calls.index).fillna(0),\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    total = feats[\"hall_calls\"].replace(0, np.nan)\n",
    "    feats[\"up_ratio\"] = (feats[\"hall_up\"] / total).fillna(0)\n",
    "    feats[\"down_ratio\"] = (feats[\"hall_down\"] / total).fillna(0)\n",
    "\n",
    "    # time cyc features\n",
    "    t = feats.index\n",
    "    minute_of_day = t.hour * 60 + t.minute\n",
    "    feats[\"sin_day\"] = np.sin(2*np.pi*minute_of_day/1440.0)\n",
    "    feats[\"cos_day\"] = np.cos(2*np.pi*minute_of_day/1440.0)\n",
    "\n",
    "    feats[\"activity\"] = feats[\"hall_calls\"] + 0.5*feats[\"stops\"] + 0.2*feats[\"departures\"]\n",
    "\n",
    "    feats = feats.reset_index().rename(columns={\"index\":\"Time\"})\n",
    "    feats[\"Time\"] = pd.to_datetime(feats[\"Time\"])\n",
    "    return feats\n",
    "\n",
    "def train_mode_cluster(feats: pd.DataFrame, n_clusters=N_CLUSTERS):\n",
    "    feature_cols = [\n",
    "        \"hall_calls\",\"up_ratio\",\"down_ratio\",\"origin_entropy\",\n",
    "        \"stops\",\"stop_entropy\",\"departures\",\n",
    "        \"load_in\",\"load_out\",\"maint_ratio\",\n",
    "        \"sin_day\",\"cos_day\",\"activity\"\n",
    "    ]\n",
    "    X = feats[feature_cols].fillna(0.0).values\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"kmeans\", KMeans(n_clusters=n_clusters, random_state=42, n_init=20))\n",
    "    ])\n",
    "    pipe.fit(X)\n",
    "    feats = feats.copy()\n",
    "    feats[\"cluster\"] = pipe.predict(X)\n",
    "    return pipe, feature_cols, feats\n",
    "\n",
    "def label_clusters(feats_with_cluster: pd.DataFrame) -> Dict[int, str]:\n",
    "    \"\"\"Map cluster -> human-readable mode label (simple explainable rules).\"\"\"\n",
    "    g = feats_with_cluster.groupby(\"cluster\").mean(numeric_only=True)\n",
    "\n",
    "    mapping = {}\n",
    "    act_q25 = g[\"activity\"].quantile(0.25)\n",
    "    act_med = g[\"activity\"].median()\n",
    "\n",
    "    for k, row in g.iterrows():\n",
    "        activity = row[\"activity\"]\n",
    "        up = row[\"up_ratio\"]\n",
    "        down = row[\"down_ratio\"]\n",
    "        ent = row[\"origin_entropy\"]\n",
    "        stop_ent = row[\"stop_entropy\"]\n",
    "\n",
    "        if activity <= act_q25:\n",
    "            label = \"Idle/Low\"\n",
    "        elif up > 0.65 and activity >= act_med:\n",
    "            label = \"Up-Peak\"\n",
    "        elif down > 0.65 and activity >= act_med:\n",
    "            label = \"Down-Peak\"\n",
    "        elif ent > 0.70 or stop_ent > 0.70:\n",
    "            label = \"Inter-floor/Meeting\"\n",
    "        else:\n",
    "            label = \"Balanced/Meal-hour\"\n",
    "        mapping[int(k)] = label\n",
    "\n",
    "    return mapping\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Learn demand weights by (mode, floor)\n",
    "# -----------------------------\n",
    "def learn_floor_demand_by_mode(hall: pd.DataFrame, feats_clustered: pd.DataFrame, freq=DECISION_FREQ):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      demand[(mode_label)][floor] = avg hall-call count per horizon window\n",
    "    \"\"\"\n",
    "    # Identify hall origin floor column\n",
    "    h_floor = pick_col(hall, [\"Floor\",\"floor\",\"OriginFloor\",\"FromFloor\",\"HallFloor\",\"StartFloor\"], required=True)\n",
    "\n",
    "    # Attach cluster/mode to each hall call by matching its 5-min slice\n",
    "    hall2 = hall.copy()\n",
    "    hall2[\"slice\"] = hall2[\"Time\"].dt.floor(freq)\n",
    "\n",
    "    cluster_map = feats_clustered.set_index(\"Time\")[\"cluster\"].to_dict()\n",
    "    hall2[\"cluster\"] = hall2[\"slice\"].map(cluster_map)\n",
    "\n",
    "    # Drop calls outside feature range\n",
    "    hall2 = hall2.dropna(subset=[\"cluster\"])\n",
    "    hall2[\"cluster\"] = hall2[\"cluster\"].astype(int)\n",
    "\n",
    "    # Count hall calls per (slice, cluster, floor)\n",
    "    counts = (\n",
    "        hall2.groupby([\"slice\",\"cluster\", hall2[h_floor]])[\"Time\"]\n",
    "             .size()\n",
    "             .rename(\"cnt\")\n",
    "             .reset_index()\n",
    "             .rename(columns={h_floor:\"floor\"})\n",
    "    )\n",
    "\n",
    "    # Average demand per slice for each cluster-floor\n",
    "    avg = counts.groupby([\"cluster\",\"floor\"])[\"cnt\"].mean().reset_index()\n",
    "\n",
    "    return avg  # columns: cluster, floor, cnt\n",
    "\n",
    "# -----------------------------\n",
    "# 4) k-median on 1D floors (choose parking floors for k idle elevators)\n",
    "# -----------------------------\n",
    "def weighted_k_median_1d(floors: np.ndarray, weights: np.ndarray, k: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Choose k facility locations on 1D line to minimize sum_i w_i * |x_i - facility(x_i)|.\n",
    "    Facilities must be at existing floor positions (integers).\n",
    "    DP solution O(k*n^2) for n unique floors, small n => OK.\n",
    "    \"\"\"\n",
    "    # Sort\n",
    "    order = np.argsort(floors)\n",
    "    x = floors[order].astype(int)\n",
    "    w = weights[order].astype(float)\n",
    "    n = len(x)\n",
    "\n",
    "    # Precompute cost[i][j] = cost of serving points i..j with 1 median facility\n",
    "    # Median index m is weighted median. For simplicity (n small), brute find best median.\n",
    "    cost = np.zeros((n, n))\n",
    "    best_m = np.zeros((n, n), dtype=int)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            idx = np.arange(i, j+1)\n",
    "            # find best median among idx\n",
    "            best = None\n",
    "            best_idx = i\n",
    "            for m in idx:\n",
    "                c = np.sum(w[idx] * np.abs(x[idx] - x[m]))\n",
    "                if best is None or c < best:\n",
    "                    best = c\n",
    "                    best_idx = m\n",
    "            cost[i, j] = best if best is not None else 0.0\n",
    "            best_m[i, j] = best_idx\n",
    "\n",
    "    # DP: dp[t][j] = min cost using t facilities to cover points 0..j\n",
    "    dp = np.full((k+1, n), np.inf)\n",
    "    prev = np.full((k+1, n), -1, dtype=int)\n",
    "\n",
    "    # base: 1 facility\n",
    "    for j in range(n):\n",
    "        dp[1, j] = cost[0, j]\n",
    "        prev[1, j] = -1\n",
    "\n",
    "    for t in range(2, k+1):\n",
    "        for j in range(n):\n",
    "            # split at p: cover 0..p with t-1, and p+1..j with 1\n",
    "            for p in range(t-2, j):\n",
    "                cand = dp[t-1, p] + cost[p+1, j]\n",
    "                if cand < dp[t, j]:\n",
    "                    dp[t, j] = cand\n",
    "                    prev[t, j] = p\n",
    "\n",
    "    # Recover segments\n",
    "    facilities = []\n",
    "    t = k\n",
    "    j = n-1\n",
    "    while t >= 1 and j >= 0:\n",
    "        p = prev[t, j]\n",
    "        i = 0 if p == -1 else p+1\n",
    "        m = best_m[i, j]\n",
    "        facilities.append(int(x[m]))\n",
    "        j = p\n",
    "        t -= 1\n",
    "\n",
    "    facilities.reverse()\n",
    "    return facilities\n",
    "\n",
    "def assign_elevators_to_targets(elevator_floors: Dict[int,int], targets: List[int]) -> Dict[int,int]:\n",
    "    \"\"\"\n",
    "    Greedy matching: assign each target to closest available elevator.\n",
    "    Returns: elevator_id -> target_floor\n",
    "    \"\"\"\n",
    "    eids = list(elevator_floors.keys())\n",
    "    remaining = set(eids)\n",
    "    assignment = {}\n",
    "\n",
    "    for tgt in targets:\n",
    "        best_e, best_d = None, None\n",
    "        for e in list(remaining):\n",
    "            d = abs(elevator_floors[e] - tgt)\n",
    "            if best_d is None or d < best_d:\n",
    "                best_d = d\n",
    "                best_e = e\n",
    "        if best_e is None:\n",
    "            break\n",
    "        assignment[best_e] = tgt\n",
    "        remaining.remove(best_e)\n",
    "\n",
    "    # Any leftover elevators (if more idle than targets): keep them where they are\n",
    "    for e in remaining:\n",
    "        assignment[e] = elevator_floors[e]\n",
    "    return assignment\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Lightweight event simulator for waiting time\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class ElevatorState:\n",
    "    floor: int\n",
    "    available_time: pd.Timestamp  # when elevator can take new call\n",
    "\n",
    "def travel_time_seconds(f1: int, f2: int) -> float:\n",
    "    return abs(int(f1) - int(f2)) * SECONDS_PER_FLOOR\n",
    "\n",
    "def infer_initial_positions(stop: pd.DataFrame, start_time: pd.Timestamp) -> Dict[int,int]:\n",
    "    \"\"\"\n",
    "    Infer elevator last known floor before start_time from car_stops.\n",
    "    Falls back to lobby if unknown.\n",
    "    \"\"\"\n",
    "    eid_col = pick_col(stop, [\"Elevator\",\"elevator\",\"CarID\",\"CarId\",\"LiftID\",\"ID\"], required=False)\n",
    "    floor_col = pick_col(stop, [\"Floor\",\"floor\",\"StopFloor\",\"AtFloor\",\"CurrentFloor\"], required=False)\n",
    "\n",
    "    pos = {i: LOBBY_FLOOR for i in range(N_ELEVATORS)}\n",
    "    if eid_col is None or floor_col is None:\n",
    "        return pos\n",
    "\n",
    "    s = stop[stop[\"Time\"] <= start_time].copy()\n",
    "    if s.empty:\n",
    "        return pos\n",
    "\n",
    "    s = s.sort_values(\"Time\")\n",
    "    last = s.groupby(eid_col).tail(1)\n",
    "    for _, r in last.iterrows():\n",
    "        try:\n",
    "            eid = int(r[eid_col])\n",
    "            pos[eid] = int(r[floor_col])\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pos\n",
    "\n",
    "def simulate(strategy: str,\n",
    "             hall: pd.DataFrame,\n",
    "             feats: pd.DataFrame,\n",
    "             mode_pipe: Pipeline,\n",
    "             mode_features: List[str],\n",
    "             cluster_to_label: Dict[int,str],\n",
    "             demand_by_cluster_floor: pd.DataFrame,\n",
    "             start_time: Optional[pd.Timestamp]=None,\n",
    "             end_time: Optional[pd.Timestamp]=None) -> Dict[str,float]:\n",
    "    \"\"\"\n",
    "    strategy in {\"last_stop\",\"lobby\",\"dynamic\"}.\n",
    "    \"\"\"\n",
    "    # columns\n",
    "    h_floor = pick_col(hall, [\"Floor\",\"floor\",\"OriginFloor\",\"FromFloor\",\"HallFloor\",\"StartFloor\"], required=True)\n",
    "\n",
    "    hall = hall.sort_values(\"Time\").copy()\n",
    "    if start_time is None:\n",
    "        start_time = hall[\"Time\"].min()\n",
    "    if end_time is None:\n",
    "        end_time = hall[\"Time\"].max()\n",
    "\n",
    "    # Filter simulation interval\n",
    "    hall_sim = hall[(hall[\"Time\"] >= start_time) & (hall[\"Time\"] <= end_time)].copy()\n",
    "    if hall_sim.empty:\n",
    "        return {\"AWT\": np.nan, \"LongWaitPct\": np.nan, \"N\": 0}\n",
    "\n",
    "    # Initial elevator states\n",
    "    # (use last stop before start_time if possible; otherwise lobby)\n",
    "    _, stop, _, _, _ = load_data()\n",
    "    init_pos = infer_initial_positions(stop, start_time)\n",
    "\n",
    "    elevators = {\n",
    "        e: ElevatorState(floor=init_pos.get(e, LOBBY_FLOOR), available_time=start_time)\n",
    "        for e in range(N_ELEVATORS)\n",
    "    }\n",
    "\n",
    "    # Precompute demand lookup: (cluster -> arrays floors, weights)\n",
    "    demand_group = demand_by_cluster_floor.groupby(\"cluster\")\n",
    "    demand_lookup = {}\n",
    "    for cl, dfc in demand_group:\n",
    "        floors = dfc[\"floor\"].astype(int).values\n",
    "        w = dfc[\"cnt\"].astype(float).values\n",
    "        # avoid all-zero\n",
    "        if w.sum() <= 0:\n",
    "            w = np.ones_like(w)\n",
    "        demand_lookup[int(cl)] = (floors, w)\n",
    "\n",
    "    waits = []\n",
    "\n",
    "    # Decision times for parking\n",
    "    decision_times = pd.date_range(start=start_time.floor(DECISION_FREQ),\n",
    "                                   end=end_time.ceil(DECISION_FREQ),\n",
    "                                   freq=DECISION_FREQ)\n",
    "\n",
    "    # Helper to get cluster at a decision time (nearest available feature row)\n",
    "    feats_idx = feats.set_index(\"Time\").sort_index()\n",
    "\n",
    "    def get_cluster_label_at(t: pd.Timestamp) -> Tuple[int,str]:\n",
    "        # use exact row if exists, else previous\n",
    "        tt = t.floor(DECISION_FREQ)\n",
    "        if tt in feats_idx.index:\n",
    "            row = feats_idx.loc[tt]\n",
    "        else:\n",
    "            # previous available\n",
    "            row = feats_idx.loc[:tt].tail(1)\n",
    "            if isinstance(row, pd.DataFrame):\n",
    "                row = row.iloc[0]\n",
    "        X = row[mode_features].fillna(0.0).values.reshape(1, -1)\n",
    "        cl = int(mode_pipe.predict(X)[0])\n",
    "        return cl, cluster_to_label.get(cl, \"Unknown\")\n",
    "\n",
    "    # Parking policy invoked at decision times\n",
    "    def apply_parking_policy(t: pd.Timestamp):\n",
    "        # Identify idle elevators (available_time <= t)\n",
    "        idle = [e for e, st in elevators.items() if st.available_time <= t]\n",
    "\n",
    "        if len(idle) == 0:\n",
    "            return\n",
    "\n",
    "        if strategy == \"last_stop\":\n",
    "            return\n",
    "\n",
    "        if strategy == \"lobby\":\n",
    "            for e in idle:\n",
    "                st = elevators[e]\n",
    "                if st.floor != LOBBY_FLOOR:\n",
    "                    tt = travel_time_seconds(st.floor, LOBBY_FLOOR)\n",
    "                    st.available_time = t + pd.Timedelta(seconds=tt)\n",
    "                    st.floor = LOBBY_FLOOR\n",
    "            return\n",
    "\n",
    "        if strategy == \"dynamic\":\n",
    "            cl, _ = get_cluster_label_at(t)\n",
    "\n",
    "            # demand for next horizon: scale weights by horizon slices\n",
    "            if cl in demand_lookup:\n",
    "                floors, w = demand_lookup[cl]\n",
    "            else:\n",
    "                # fallback to global\n",
    "                allf = demand_by_cluster_floor.groupby(\"floor\")[\"cnt\"].mean().reset_index()\n",
    "                floors = allf[\"floor\"].astype(int).values\n",
    "                w = allf[\"cnt\"].astype(float).values\n",
    "                if w.sum() <= 0:\n",
    "                    w = np.ones_like(w)\n",
    "\n",
    "            # Choose k target parking floors for number of idle elevators\n",
    "            k = min(len(idle), N_ELEVATORS)\n",
    "            # Reduce to unique floors if too many\n",
    "            if len(floors) == 0:\n",
    "                targets = [LOBBY_FLOOR] * k\n",
    "            else:\n",
    "                # If floors extremely many, keep top by weight to stabilize DP\n",
    "                if len(floors) > 60:\n",
    "                    top_idx = np.argsort(-w)[:60]\n",
    "                    floors2, w2 = floors[top_idx], w[top_idx]\n",
    "                else:\n",
    "                    floors2, w2 = floors, w\n",
    "\n",
    "                # normalize weights\n",
    "                w2 = w2 / (w2.sum() + 1e-12)\n",
    "\n",
    "                # Compute k-median targets\n",
    "                targets = weighted_k_median_1d(floors2, w2, k)\n",
    "\n",
    "            # Assign idle elevators to targets\n",
    "            cur_pos = {e: elevators[e].floor for e in idle}\n",
    "            assignment = assign_elevators_to_targets(cur_pos, targets)\n",
    "\n",
    "            for e, tgt in assignment.items():\n",
    "                st = elevators[e]\n",
    "                if st.floor != tgt:\n",
    "                    tt = travel_time_seconds(st.floor, tgt)\n",
    "                    st.available_time = t + pd.Timedelta(seconds=tt)\n",
    "                    st.floor = tgt\n",
    "\n",
    "    # Simulation loop over calls; we also apply parking at decision points\n",
    "    decision_ptr = 0\n",
    "    decision_times = list(decision_times)\n",
    "\n",
    "    for _, call in hall_sim.iterrows():\n",
    "        call_time = call[\"Time\"]\n",
    "        origin_floor = int(call[h_floor])\n",
    "\n",
    "        # Apply parking decisions up to this call_time\n",
    "        while decision_ptr < len(decision_times) and decision_times[decision_ptr] <= call_time:\n",
    "            apply_parking_policy(decision_times[decision_ptr])\n",
    "            decision_ptr += 1\n",
    "\n",
    "        # Choose an elevator to serve this call:\n",
    "        # minimize arrival time = max(available_time, call_time) + travel_time(current_floor -> origin)\n",
    "        best_e = None\n",
    "        best_arrival = None\n",
    "\n",
    "        for e, st in elevators.items():\n",
    "            start_service = max(st.available_time, call_time)\n",
    "            arr = start_service + pd.Timedelta(seconds=travel_time_seconds(st.floor, origin_floor))\n",
    "            if best_arrival is None or arr < best_arrival:\n",
    "                best_arrival = arr\n",
    "                best_e = e\n",
    "\n",
    "        # Waiting time: arrival - call_time (doors open assumed at arrival + DOOR_TIME doesn't affect waiting-to-arrival)\n",
    "        wait_sec = (best_arrival - call_time).total_seconds()\n",
    "        waits.append(wait_sec)\n",
    "\n",
    "        # Update chosen elevator state: after serving, elevator stays at origin floor, becomes available after door time\n",
    "        st = elevators[best_e]\n",
    "        st.floor = origin_floor\n",
    "        st.available_time = best_arrival + pd.Timedelta(seconds=DOOR_TIME)\n",
    "\n",
    "    waits = np.array(waits, dtype=float)\n",
    "    awt = float(np.mean(waits)) if len(waits) else np.nan\n",
    "    long_pct = float(np.mean(waits >= LONG_WAIT_THRESHOLD) * 100.0) if len(waits) else np.nan\n",
    "\n",
    "    return {\"AWT\": awt, \"LongWaitPct\": long_pct, \"N\": int(len(waits))}\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Train everything + run comparison\n",
    "# -----------------------------\n",
    "def run_task3_demo():\n",
    "    hall, _, _, _, _ = load_data()\n",
    "\n",
    "    # (A) Build mode features + cluster model\n",
    "    feats = build_5min_features()\n",
    "    mode_pipe, mode_features, feats_clustered = train_mode_cluster(feats, n_clusters=N_CLUSTERS)\n",
    "    cl_to_label = label_clusters(feats_clustered)\n",
    "\n",
    "    # (B) Learn demand by (cluster, floor)\n",
    "    demand = learn_floor_demand_by_mode(hall, feats_clustered)\n",
    "\n",
    "    # (C) Choose a simulation window (e.g., last 3 days) to keep runtime reasonable\n",
    "    # You can expand to full 30 days once happy.\n",
    "    tmin = hall[\"Time\"].min()\n",
    "    tmax = hall[\"Time\"].max()\n",
    "    sim_start = max(tmin, tmax - pd.Timedelta(days=3))\n",
    "    sim_end = tmax\n",
    "\n",
    "    # (D) Evaluate strategies\n",
    "    results = {}\n",
    "    for strat in [\"last_stop\", \"lobby\", \"dynamic\"]:\n",
    "        res = simulate(\n",
    "            strategy=strat,\n",
    "            hall=hall,\n",
    "            feats=feats_clustered,\n",
    "            mode_pipe=mode_pipe,\n",
    "            mode_features=mode_features,\n",
    "            cluster_to_label=cl_to_label,\n",
    "            demand_by_cluster_floor=demand,\n",
    "            start_time=sim_start,\n",
    "            end_time=sim_end\n",
    "        )\n",
    "        results[strat] = res\n",
    "\n",
    "    print(\"\\n========== Task3 Strategy Comparison ==========\")\n",
    "    print(f\"Simulation window: {sim_start}  ->  {sim_end}\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"{k:>10} | AWT={v['AWT']:.2f}s | LongWait%={v['LongWaitPct']:.2f}% | N={v['N']}\")\n",
    "\n",
    "    # Save artifacts useful for report\n",
    "    feats_clustered.to_csv(\"task3_mode_features_5min.csv\", index=False)\n",
    "    demand.to_csv(\"task3_demand_cluster_floor.csv\", index=False)\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_task3_demo()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
