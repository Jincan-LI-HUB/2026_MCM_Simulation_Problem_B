{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup-outputs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT    = E:\\canfiles\\Competitions\\math_modeling\\2026_1_19_MCM_simulation\\Problem_B\\project\n",
      "OUT_DATA= E:\\canfiles\\Competitions\\math_modeling\\2026_1_19_MCM_simulation\\Problem_B\\project\\outputs\\data\n",
      "OUT_FIG = E:\\canfiles\\Competitions\\math_modeling\\2026_1_19_MCM_simulation\\Problem_B\\project\\outputs\\fig\n",
      "OUT_TAB = E:\\canfiles\\Competitions\\math_modeling\\2026_1_19_MCM_simulation\\Problem_B\\project\\outputs\\tab\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ===== Output directories (for figures/tables/data used in LaTeX) =====\n",
    "ROOT = Path.cwd()  # if this is not your project root, change it manually\n",
    "OUT_DIR = ROOT / 'outputs'\n",
    "OUT_DATA = OUT_DIR / 'data'\n",
    "OUT_FIG  = OUT_DIR / 'fig'\n",
    "OUT_TAB  = OUT_DIR / 'tab'\n",
    "\n",
    "OUT_DATA.mkdir(parents=True, exist_ok=True)\n",
    "OUT_FIG.mkdir(parents=True, exist_ok=True)\n",
    "OUT_TAB.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('ROOT    =', ROOT)\n",
    "print('OUT_DATA=', OUT_DATA)\n",
    "print('OUT_FIG =', OUT_FIG)\n",
    "print('OUT_TAB =', OUT_TAB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b224f7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Task1 Result ==========\n",
      "FLOW_MODE = hall_calls\n",
      "Test MAE  = 4.7576\n",
      "Test RMSE = 8.6967\n",
      "Saved Task1 prediction series to: E:\\canfiles\\Competitions\\math_modeling\\2026_1_19_MCM_simulation\\Problem_B\\project\\outputs\\data\\task1_pred_series.csv\n",
      "Saved model to: task1_flow_model.joblib\n",
      "Next slice time: 2025-11-30 22:55:00\n",
      "Predicted flow : 0.3875\n"
     ]
    }
   ],
   "source": [
    "# Task1: Predict total passenger flow volume for the next 5-minute time slice\n",
    "# Based on cleaned CSVs:\n",
    "# /mnt/data/hall_calls_clean.csv\n",
    "# /mnt/data/load_changes_clean.csv\n",
    "# /mnt/data/car_calls_clean.csv\n",
    "# /mnt/data/car_stops_clean.csv\n",
    "# /mnt/data/car_departures_clean.csv\n",
    "# /mnt/data/maintenance_mode_clean.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"8\"  # 改成你电脑想用的核心数（比如 8）\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Paths\n",
    "# -----------------------------\n",
    "PATH_HALL = \"data/clean/hall_calls_clean.csv\"\n",
    "PATH_LOAD = \"data/clean/load_changes_clean.csv\"\n",
    "PATH_MAINT = \"data/clean/maintenance_mode_clean.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Config\n",
    "# -----------------------------\n",
    "FREQ = \"5min\"\n",
    "\n",
    "# 客流定义方式：\n",
    "# \"hall_calls\" = 每5分钟 hall call 数（推荐）\n",
    "# \"load_in\"    = 每5分钟 Load In 总重量 / avg_weight 估算人数（需要你确认单位与平均体重）\n",
    "FLOW_MODE = \"hall_calls\"\n",
    "\n",
    "# 仅在 FLOW_MODE=\"load_in\" 时使用：平均乘客体重（单位要与 Load In 一致）\n",
    "AVG_PASSENGER_WEIGHT = 65.0  # 例如 65 kg（如果 Load In 是 kg）；不确定请改成你们合理数值\n",
    "\n",
    "# 滞后特征：用过去多少个 5-min 片段\n",
    "LAGS = [1, 2, 3, 6, 12]  # 5/10/15/30/60分钟\n",
    "ROLL_WINDOWS = [3, 6, 12]  # rolling mean window size in slices\n",
    "\n",
    "# 训练集比例（按时间顺序切分）\n",
    "TRAIN_RATIO = 0.85\n",
    "\n",
    "MODEL_OUT = \"task1_flow_model.joblib\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Helpers\n",
    "# -----------------------------\n",
    "def add_time_features(df: pd.DataFrame, time_col=\"Time\") -> pd.DataFrame:\n",
    "    \"\"\"加入能适应一天不同时段的周期特征\"\"\"\n",
    "    out = df.copy()\n",
    "    t = out[time_col]\n",
    "\n",
    "    out[\"hour\"] = t.dt.hour\n",
    "    out[\"minute\"] = t.dt.minute\n",
    "    out[\"dow\"] = t.dt.dayofweek  # Monday=0\n",
    "\n",
    "    # 一天的分钟数 [0, 1440)\n",
    "    minute_of_day = out[\"hour\"] * 60 + out[\"minute\"]\n",
    "    # 周期编码：sin/cos（适应昼夜规律）\n",
    "    out[\"sin_day\"] = np.sin(2 * np.pi * minute_of_day / 1440.0)\n",
    "    out[\"cos_day\"] = np.cos(2 * np.pi * minute_of_day / 1440.0)\n",
    "\n",
    "    # 一周周期（可选）\n",
    "    out[\"sin_week\"] = np.sin(2 * np.pi * out[\"dow\"] / 7.0)\n",
    "    out[\"cos_week\"] = np.cos(2 * np.pi * out[\"dow\"] / 7.0)\n",
    "\n",
    "    # 是否工作日\n",
    "    out[\"is_weekend\"] = (out[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_lag_features(df: pd.DataFrame, y_col=\"y\") -> pd.DataFrame:\n",
    "    \"\"\"滞后 + 滚动统计特征\"\"\"\n",
    "    out = df.copy()\n",
    "    for lag in LAGS:\n",
    "        out[f\"lag_{lag}\"] = out[y_col].shift(lag)\n",
    "\n",
    "    for w in ROLL_WINDOWS:\n",
    "        out[f\"roll_mean_{w}\"] = out[y_col].shift(1).rolling(w).mean()\n",
    "        out[f\"roll_std_{w}\"] = out[y_col].shift(1).rolling(w).std()\n",
    "\n",
    "    # 简单趋势：最近1小时与前1小时差（如果有足够数据）\n",
    "    if 12 in LAGS:\n",
    "        out[\"trend_1h\"] = out[\"lag_1\"] - out[\"lag_12\"]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_flow_series(freq=FREQ, mode=FLOW_MODE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    构造 5分钟总客流时间序列。\n",
    "    mode:\n",
    "      - hall_calls: 每5min hall_calls数量\n",
    "      - load_in: 每5min Load In/avg_weight 估算“进电梯人数”\n",
    "    \"\"\"\n",
    "    if mode == \"hall_calls\":\n",
    "        hall = pd.read_csv(PATH_HALL)\n",
    "        hall[\"Time\"] = pd.to_datetime(hall[\"Time\"])\n",
    "        # 5分钟聚合：数量\n",
    "        s = hall.set_index(\"Time\").resample(freq).size().rename(\"y\").to_frame()\n",
    "\n",
    "    elif mode == \"load_in\":\n",
    "        load = pd.read_csv(PATH_LOAD)\n",
    "        load[\"Time\"] = pd.to_datetime(load[\"Time\"])\n",
    "        # 5分钟聚合：Load In 总重量 -> 估计人数\n",
    "        s = load.set_index(\"Time\")[\"Load In\"].resample(freq).sum().fillna(0)\n",
    "        s = (s / AVG_PASSENGER_WEIGHT).rename(\"y\").to_frame()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"FLOW_MODE must be 'hall_calls' or 'load_in'\")\n",
    "\n",
    "    # 补齐缺失时间片\n",
    "    s = s.asfreq(freq, fill_value=0).reset_index().rename(columns={\"Time\": \"Time\"})\n",
    "    return s\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Train + Evaluate + Predict\n",
    "# -----------------------------\n",
    "def train_task1():\n",
    "    # 3.1 Build target series\n",
    "    df = build_flow_series()\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "\n",
    "    # 3.2 Add features\n",
    "    df = add_time_features(df, \"Time\")\n",
    "    df = add_lag_features(df, \"y\")\n",
    "\n",
    "    # 3.3 Drop rows with NaNs due to lag/rolling\n",
    "    df_feat = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    feature_cols = [\n",
    "        \"sin_day\", \"cos_day\", \"sin_week\", \"cos_week\", \"is_weekend\",\n",
    "        \"hour\", \"minute\",\n",
    "    ] + [f\"lag_{l}\" for l in LAGS] + \\\n",
    "        [f\"roll_mean_{w}\" for w in ROLL_WINDOWS] + \\\n",
    "        [f\"roll_std_{w}\" for w in ROLL_WINDOWS] + ([\"trend_1h\"] if \"trend_1h\" in df_feat.columns else [])\n",
    "\n",
    "    X = df_feat[feature_cols].values\n",
    "    y = df_feat[\"y\"].values\n",
    "\n",
    "    # 3.4 Time-based split\n",
    "    n = len(df_feat)\n",
    "    n_train = int(n * TRAIN_RATIO)\n",
    "\n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_test, y_test = X[n_train:], y[n_train:]\n",
    "\n",
    "    # 3.5 Model\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        loss=\"squared_error\",\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        max_iter=400,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 3.6 Evaluate\n",
    "    pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "\n",
    "    print(\"========== Task1 Result ==========\")\n",
    "    print(f\"FLOW_MODE = {FLOW_MODE}\")\n",
    "    print(f\"Test MAE  = {mae:.4f}\")\n",
    "    print(f\"Test RMSE = {rmse:.4f}\")\n",
    "\n",
    "    \n",
    "    # 3.6b Export series for report figures (test window)\n",
    "    try:\n",
    "        test_time = df_feat[\"Time\"].iloc[n_train:].reset_index(drop=True)\n",
    "        task1_pred_df = pd.DataFrame({\n",
    "            \"Time\": test_time,\n",
    "            \"y_true\": y_test,\n",
    "            \"y_pred\": pred\n",
    "        })\n",
    "        out_csv = str(OUT_DATA / \"task1_pred_series.csv\")\n",
    "        task1_pred_df.to_csv(out_csv, index=False)\n",
    "        print(f\"Saved Task1 prediction series to: {out_csv}\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Task1 export failed:\", e)\n",
    "\n",
    "# 3.7 Save\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"feature_cols\": feature_cols,\n",
    "        \"freq\": FREQ,\n",
    "        \"flow_mode\": FLOW_MODE,\n",
    "        \"avg_passenger_weight\": AVG_PASSENGER_WEIGHT,\n",
    "        \"lags\": LAGS,\n",
    "        \"roll_windows\": ROLL_WINDOWS\n",
    "    }\n",
    "    joblib.dump(payload, MODEL_OUT)\n",
    "    print(f\"Saved model to: {MODEL_OUT}\")\n",
    "\n",
    "    # 3.8 Predict next 5-min slice using the latest available time slice\n",
    "    next_pred, next_time = predict_next(df, payload)\n",
    "    print(f\"Next slice time: {next_time}\")\n",
    "    print(f\"Predicted flow : {next_pred:.4f}\")\n",
    "\n",
    "    return payload\n",
    "\n",
    "\n",
    "def predict_next(raw_df: pd.DataFrame, payload: dict):\n",
    "    \"\"\"\n",
    "    raw_df: dataframe with columns [Time, y] at 5min freq (may include other cols)\n",
    "    \"\"\"\n",
    "    model = payload[\"model\"]\n",
    "    feature_cols = payload[\"feature_cols\"]\n",
    "\n",
    "    df = raw_df.copy()\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "\n",
    "    # Rebuild features the same way\n",
    "    df = add_time_features(df, \"Time\")\n",
    "    df = add_lag_features(df, \"y\")\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Take last row as \"current time slice\", then we predict next one by creating next time row\n",
    "    last = df.iloc[-1:].copy()\n",
    "    last_time = last[\"Time\"].iloc[0]\n",
    "    next_time = last_time + pd.Timedelta(FREQ)\n",
    "\n",
    "    # Create a new row for next_time with y unknown, but lag features come from history\n",
    "    next_row = pd.DataFrame({\"Time\": [next_time], \"y\": [np.nan]})\n",
    "    next_row = add_time_features(next_row, \"Time\")\n",
    "\n",
    "    # Build lag/rolling features for next time based on existing y series\n",
    "    y_series = df.set_index(\"Time\")[\"y\"].copy()\n",
    "\n",
    "    # Fill lag features\n",
    "    for lag in LAGS:\n",
    "        next_row[f\"lag_{lag}\"] = y_series.iloc[-lag] if len(y_series) >= lag else np.nan\n",
    "\n",
    "    # Fill rolling features\n",
    "    for w in ROLL_WINDOWS:\n",
    "        vals = y_series.iloc[-w:] if len(y_series) >= w else y_series\n",
    "        next_row[f\"roll_mean_{w}\"] = vals.mean() if len(vals) > 0 else np.nan\n",
    "        next_row[f\"roll_std_{w}\"] = vals.std() if len(vals) > 1 else 0.0\n",
    "\n",
    "    if \"trend_1h\" in feature_cols:\n",
    "        if len(y_series) >= 12:\n",
    "            next_row[\"trend_1h\"] = y_series.iloc[-1] - y_series.iloc[-12]\n",
    "        else:\n",
    "            next_row[\"trend_1h\"] = 0.0\n",
    "\n",
    "    # Ensure all required features exist\n",
    "    for c in feature_cols:\n",
    "        if c not in next_row.columns:\n",
    "            next_row[c] = 0.0\n",
    "\n",
    "    X_next = next_row[feature_cols].values\n",
    "    pred_next = model.predict(X_next)[0]\n",
    "    return float(pred_next), str(next_time)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_task1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ac7657",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (2450366802.py, line 648)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 648\u001b[1;36m\u001b[0m\n\u001b[1;33m    return results\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# Task3: Dynamic Parking Strategy Model (with a lightweight, reproducible simulator)\n",
    "# ------------------------------------------------------------\n",
    "# Uses your cleaned logs to:\n",
    "# 1) Learn demand-by-floor patterns conditioned on \"building mode\" (from Task2-style features)\n",
    "# 2) Build a Dynamic Parking Policy (k-median on floors with predicted demand weights)\n",
    "# 3) Simulate and compare 3 strategies:\n",
    "#    - \"last_stop\": do nothing (idle stays where it is)\n",
    "#    - \"lobby\": send idle elevators to lobby (floor=1)\n",
    "#    - \"dynamic\": mode-aware k-median parking floors + assignment\n",
    "#\n",
    "# Outputs:\n",
    "# - Average Waiting Time (AWT) and % Long Waits (>=60s) for each strategy\n",
    "#\n",
    "# Files used (cleaned CSV):\n",
    "# /mnt/data/hall_calls_clean.csv\n",
    "# /mnt/data/car_stops_clean.csv\n",
    "# /mnt/data/car_departures_clean.csv\n",
    "# /mnt/data/load_changes_clean.csv\n",
    "# /mnt/data/maintenance_mode_clean.csv\n",
    "# /mnt/data/car_calls_clean.csv  (optional here; not needed for basic simulation)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "PATH_HALL = \"data/clean/hall_calls_clean.csv\"\n",
    "PATH_STOP = \"data/clean/car_stops_clean.csv\"\n",
    "PATH_DEP  = \"data/clean/car_departures_clean.csv\"\n",
    "PATH_LOAD = \"data/clean/load_changes_clean.csv\"\n",
    "PATH_MAINT= \"data/clean/maintenance_mode_clean.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# Config (tune if you want)\n",
    "# -----------------------------\n",
    "N_ELEVATORS = 8\n",
    "LOBBY_FLOOR = 1\n",
    "\n",
    "# \"Realistic-ish\" travel parameters (you can tune)\n",
    "SECONDS_PER_FLOOR = 1.5     # travel time per floor\n",
    "DOOR_TIME = 8.0             # open + dwell + close\n",
    "LONG_WAIT_THRESHOLD = 60.0  # seconds\n",
    "\n",
    "# Parking decision cadence / prediction horizon\n",
    "DECISION_FREQ = \"5min\"\n",
    "PRED_HORIZON_MIN = 15       # demand for next 15 minutes to choose parking\n",
    "\n",
    "# Cluster count for \"mode\" discovery\n",
    "N_CLUSTERS = 6\n",
    "\n",
    "# -----------------------------\n",
    "# Robust column pickers\n",
    "# -----------------------------\n",
    "def pick_col(df, candidates, required=False):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Missing required column. Tried: {candidates}\")\n",
    "    return None\n",
    "\n",
    "def normalize_direction(series):\n",
    "    \"\"\"Return +1 (Up), -1 (Down), 0 (Unknown).\"\"\"\n",
    "    s = series\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return pd.Series(np.where(s > 0, 1, np.where(s < 0, -1, 0)), index=s.index)\n",
    "    ss = s.astype(str).str.lower()\n",
    "    up = ss.str.contains(\"up\") | ss.str.fullmatch(\"u\") | ss.str.contains(\"↑\")\n",
    "    down = ss.str.contains(\"down\") | ss.str.fullmatch(\"d\") | ss.str.contains(\"↓\")\n",
    "    return pd.Series(np.where(up, 1, np.where(down, -1, 0)), index=s.index)\n",
    "\n",
    "def floor_entropy(values):\n",
    "    v = pd.Series(values).dropna()\n",
    "    if len(v) == 0:\n",
    "        return 0.0\n",
    "    counts = v.value_counts()\n",
    "    p = counts / counts.sum()\n",
    "    ent = -(p * np.log(p + 1e-12)).sum()\n",
    "    return float(ent / (np.log(len(counts) + 1e-12)))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load + standardize times\n",
    "# -----------------------------\n",
    "def load_data():\n",
    "    hall = pd.read_csv(PATH_HALL)\n",
    "    stop = pd.read_csv(PATH_STOP)\n",
    "    dep  = pd.read_csv(PATH_DEP)\n",
    "    load = pd.read_csv(PATH_LOAD)\n",
    "    maint= pd.read_csv(PATH_MAINT)\n",
    "\n",
    "    for df in [hall, stop, dep, load, maint]:\n",
    "        tcol = pick_col(df, [\"Time\", \"time\", \"timestamp\", \"Datetime\", \"DateTime\"], required=True)\n",
    "        df[\"Time\"] = pd.to_datetime(df[tcol])\n",
    "\n",
    "    return hall, stop, dep, load, maint\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build 5-min features (Task2-style) for mode clustering\n",
    "# -----------------------------\n",
    "def build_5min_features(freq=DECISION_FREQ):\n",
    "    hall, stop, dep, load, maint = load_data()\n",
    "\n",
    "    # Hall calls\n",
    "    h_dir = pick_col(hall, [\"Direction\",\"direction\",\"CallDirection\",\"HallDirection\",\"UpDown\",\"dir\"])\n",
    "    h_floor = pick_col(hall, [\"Floor\",\"floor\",\"OriginFloor\",\"FromFloor\",\"HallFloor\",\"StartFloor\"], required=True)\n",
    "    h = hall.set_index(\"Time\")\n",
    "\n",
    "    hall_calls = h.resample(freq).size().rename(\"hall_calls\")\n",
    "    if h_dir:\n",
    "        d = normalize_direction(h[h_dir])\n",
    "        hall_up = (d == 1).resample(freq).sum().rename(\"hall_up\")\n",
    "        hall_down = (d == -1).resample(freq).sum().rename(\"hall_down\")\n",
    "    else:\n",
    "        hall_up = pd.Series(index=hall_calls.index, data=0.0, name=\"hall_up\")\n",
    "        hall_down = pd.Series(index=hall_calls.index, data=0.0, name=\"hall_down\")\n",
    "\n",
    "    hall_ent = h[h_floor].resample(freq).apply(floor_entropy).rename(\"origin_entropy\")\n",
    "\n",
    "    # Stops\n",
    "    s = stop.set_index(\"Time\")\n",
    "    s_floor = pick_col(stop, [\"Floor\",\"floor\",\"StopFloor\",\"AtFloor\",\"CurrentFloor\"])\n",
    "    stops = s.resample(freq).size().rename(\"stops\")\n",
    "    if s_floor:\n",
    "        # \"stop entropy\" can proxy spread of served floors\n",
    "        stop_ent = s[s_floor].resample(freq).apply(floor_entropy).rename(\"stop_entropy\")\n",
    "    else:\n",
    "        stop_ent = pd.Series(index=hall_calls.index, data=0.0, name=\"stop_entropy\")\n",
    "\n",
    "    # Departures\n",
    "    d = dep.set_index(\"Time\")\n",
    "    departures = d.resample(freq).size().rename(\"departures\")\n",
    "\n",
    "    # Load changes\n",
    "    ld = load.set_index(\"Time\")\n",
    "    in_col = pick_col(load, [\"Load In\",\"LoadIn\",\"load_in\",\"InLoad\",\"WeightIn\"])\n",
    "    out_col= pick_col(load, [\"Load Out\",\"LoadOut\",\"load_out\",\"OutLoad\",\"WeightOut\"])\n",
    "    load_in = ld[in_col].resample(freq).sum().fillna(0).rename(\"load_in\") if in_col else pd.Series(index=hall_calls.index, data=0.0, name=\"load_in\")\n",
    "    load_out= ld[out_col].resample(freq).sum().fillna(0).rename(\"load_out\") if out_col else pd.Series(index=hall_calls.index, data=0.0, name=\"load_out\")\n",
    "\n",
    "    # Maintenance ratio (rough)\n",
    "    m = maint.set_index(\"Time\")\n",
    "    m_flag = pick_col(maint, [\"Maintenance\",\"maintenance\",\"IsMaintenance\",\"MaintMode\",\"Mode\"])\n",
    "    m_eid  = pick_col(maint, [\"Elevator\",\"elevator\",\"CarID\",\"CarId\",\"LiftID\",\"ID\"])\n",
    "    if m_flag and m_eid:\n",
    "        mm = m.copy()\n",
    "        mm[\"maint_flag\"] = (\n",
    "            mm[m_flag].astype(int) if pd.api.types.is_numeric_dtype(mm[m_flag])\n",
    "            else mm[m_flag].astype(str).str.lower().isin([\"1\",\"true\",\"yes\",\"maint\",\"maintenance\"]).astype(int)\n",
    "        )\n",
    "        maint_ratio = (\n",
    "            mm.groupby([pd.Grouper(freq=freq), m_eid])[\"maint_flag\"].last()\n",
    "              .groupby(level=0).mean()\n",
    "              .reindex(hall_calls.index).fillna(method=\"ffill\").fillna(0)\n",
    "              .rename(\"maint_ratio\")\n",
    "        )\n",
    "    else:\n",
    "        maint_ratio = pd.Series(index=hall_calls.index, data=0.0, name=\"maint_ratio\")\n",
    "\n",
    "    feats = pd.concat(\n",
    "        [\n",
    "            hall_calls,\n",
    "            hall_up.reindex(hall_calls.index).fillna(0),\n",
    "            hall_down.reindex(hall_calls.index).fillna(0),\n",
    "            hall_ent.reindex(hall_calls.index).fillna(0),\n",
    "            stops.reindex(hall_calls.index).fillna(0),\n",
    "            stop_ent.reindex(hall_calls.index).fillna(0),\n",
    "            departures.reindex(hall_calls.index).fillna(0),\n",
    "            load_in.reindex(hall_calls.index).fillna(0),\n",
    "            load_out.reindex(hall_calls.index).fillna(0),\n",
    "            maint_ratio.reindex(hall_calls.index).fillna(0),\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    total = feats[\"hall_calls\"].replace(0, np.nan)\n",
    "    feats[\"up_ratio\"] = (feats[\"hall_up\"] / total).fillna(0)\n",
    "    feats[\"down_ratio\"] = (feats[\"hall_down\"] / total).fillna(0)\n",
    "\n",
    "    # time cyc features\n",
    "    t = feats.index\n",
    "    minute_of_day = t.hour * 60 + t.minute\n",
    "    feats[\"sin_day\"] = np.sin(2*np.pi*minute_of_day/1440.0)\n",
    "    feats[\"cos_day\"] = np.cos(2*np.pi*minute_of_day/1440.0)\n",
    "\n",
    "    feats[\"activity\"] = feats[\"hall_calls\"] + 0.5*feats[\"stops\"] + 0.2*feats[\"departures\"]\n",
    "\n",
    "    feats = feats.reset_index().rename(columns={\"index\":\"Time\"})\n",
    "    feats[\"Time\"] = pd.to_datetime(feats[\"Time\"])\n",
    "    return feats\n",
    "\n",
    "def train_mode_cluster(feats: pd.DataFrame, n_clusters=N_CLUSTERS):\n",
    "    feature_cols = [\n",
    "        \"hall_calls\",\"up_ratio\",\"down_ratio\",\"origin_entropy\",\n",
    "        \"stops\",\"stop_entropy\",\"departures\",\n",
    "        \"load_in\",\"load_out\",\"maint_ratio\",\n",
    "        \"sin_day\",\"cos_day\",\"activity\"\n",
    "    ]\n",
    "    X = feats[feature_cols].fillna(0.0).values\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"kmeans\", KMeans(n_clusters=n_clusters, random_state=42, n_init=20))\n",
    "    ])\n",
    "    pipe.fit(X)\n",
    "    feats = feats.copy()\n",
    "    feats[\"cluster\"] = pipe.predict(X)\n",
    "    return pipe, feature_cols, feats\n",
    "\n",
    "def label_clusters(feats_with_cluster: pd.DataFrame) -> Dict[int, str]:\n",
    "    \"\"\"Map cluster -> human-readable mode label (simple explainable rules).\"\"\"\n",
    "    g = feats_with_cluster.groupby(\"cluster\").mean(numeric_only=True)\n",
    "\n",
    "    mapping = {}\n",
    "    act_q25 = g[\"activity\"].quantile(0.25)\n",
    "    act_med = g[\"activity\"].median()\n",
    "\n",
    "    for k, row in g.iterrows():\n",
    "        activity = row[\"activity\"]\n",
    "        up = row[\"up_ratio\"]\n",
    "        down = row[\"down_ratio\"]\n",
    "        ent = row[\"origin_entropy\"]\n",
    "        stop_ent = row[\"stop_entropy\"]\n",
    "\n",
    "        if activity <= act_q25:\n",
    "            label = \"Idle/Low\"\n",
    "        elif up > 0.65 and activity >= act_med:\n",
    "            label = \"Up-Peak\"\n",
    "        elif down > 0.65 and activity >= act_med:\n",
    "            label = \"Down-Peak\"\n",
    "        elif ent > 0.70 or stop_ent > 0.70:\n",
    "            label = \"Inter-floor/Meeting\"\n",
    "        else:\n",
    "            label = \"Balanced/Meal-hour\"\n",
    "        mapping[int(k)] = label\n",
    "\n",
    "    return mapping\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Learn demand weights by (mode, floor)\n",
    "# -----------------------------\n",
    "def learn_floor_demand_by_mode(hall: pd.DataFrame, feats_clustered: pd.DataFrame, freq=DECISION_FREQ):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      demand[(mode_label)][floor] = avg hall-call count per horizon window\n",
    "    \"\"\"\n",
    "    # Identify hall origin floor column\n",
    "    h_floor = pick_col(hall, [\"Floor\",\"floor\",\"OriginFloor\",\"FromFloor\",\"HallFloor\",\"StartFloor\"], required=True)\n",
    "\n",
    "    # Attach cluster/mode to each hall call by matching its 5-min slice\n",
    "    hall2 = hall.copy()\n",
    "    hall2[\"slice\"] = hall2[\"Time\"].dt.floor(freq)\n",
    "\n",
    "    cluster_map = feats_clustered.set_index(\"Time\")[\"cluster\"].to_dict()\n",
    "    hall2[\"cluster\"] = hall2[\"slice\"].map(cluster_map)\n",
    "\n",
    "    # Drop calls outside feature range\n",
    "    hall2 = hall2.dropna(subset=[\"cluster\"])\n",
    "    hall2[\"cluster\"] = hall2[\"cluster\"].astype(int)\n",
    "\n",
    "    # Count hall calls per (slice, cluster, floor)\n",
    "    counts = (\n",
    "        hall2.groupby([\"slice\",\"cluster\", hall2[h_floor]])[\"Time\"]\n",
    "             .size()\n",
    "             .rename(\"cnt\")\n",
    "             .reset_index()\n",
    "             .rename(columns={h_floor:\"floor\"})\n",
    "    )\n",
    "\n",
    "    # Average demand per slice for each cluster-floor\n",
    "    avg = counts.groupby([\"cluster\",\"floor\"])[\"cnt\"].mean().reset_index()\n",
    "\n",
    "    return avg  # columns: cluster, floor, cnt\n",
    "\n",
    "# -----------------------------\n",
    "# 4) k-median on 1D floors (choose parking floors for k idle elevators)\n",
    "# -----------------------------\n",
    "def weighted_k_median_1d(floors: np.ndarray, weights: np.ndarray, k: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Choose k facility locations on 1D line to minimize sum_i w_i * |x_i - facility(x_i)|.\n",
    "    Facilities must be at existing floor positions (integers).\n",
    "    DP solution O(k*n^2) for n unique floors, small n => OK.\n",
    "    \"\"\"\n",
    "    # Sort\n",
    "    order = np.argsort(floors)\n",
    "    x = floors[order].astype(int)\n",
    "    w = weights[order].astype(float)\n",
    "    n = len(x)\n",
    "\n",
    "    # Precompute cost[i][j] = cost of serving points i..j with 1 median facility\n",
    "    # Median index m is weighted median. For simplicity (n small), brute find best median.\n",
    "    cost = np.zeros((n, n))\n",
    "    best_m = np.zeros((n, n), dtype=int)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            idx = np.arange(i, j+1)\n",
    "            # find best median among idx\n",
    "            best = None\n",
    "            best_idx = i\n",
    "            for m in idx:\n",
    "                c = np.sum(w[idx] * np.abs(x[idx] - x[m]))\n",
    "                if best is None or c < best:\n",
    "                    best = c\n",
    "                    best_idx = m\n",
    "            cost[i, j] = best if best is not None else 0.0\n",
    "            best_m[i, j] = best_idx\n",
    "\n",
    "    # DP: dp[t][j] = min cost using t facilities to cover points 0..j\n",
    "    dp = np.full((k+1, n), np.inf)\n",
    "    prev = np.full((k+1, n), -1, dtype=int)\n",
    "\n",
    "    # base: 1 facility\n",
    "    for j in range(n):\n",
    "        dp[1, j] = cost[0, j]\n",
    "        prev[1, j] = -1\n",
    "\n",
    "    for t in range(2, k+1):\n",
    "        for j in range(n):\n",
    "            # split at p: cover 0..p with t-1, and p+1..j with 1\n",
    "            for p in range(t-2, j):\n",
    "                cand = dp[t-1, p] + cost[p+1, j]\n",
    "                if cand < dp[t, j]:\n",
    "                    dp[t, j] = cand\n",
    "                    prev[t, j] = p\n",
    "\n",
    "    # Recover segments\n",
    "    facilities = []\n",
    "    t = k\n",
    "    j = n-1\n",
    "    while t >= 1 and j >= 0:\n",
    "        p = prev[t, j]\n",
    "        i = 0 if p == -1 else p+1\n",
    "        m = best_m[i, j]\n",
    "        facilities.append(int(x[m]))\n",
    "        j = p\n",
    "        t -= 1\n",
    "\n",
    "    facilities.reverse()\n",
    "    return facilities\n",
    "\n",
    "def assign_elevators_to_targets(elevator_floors: Dict[int,int], targets: List[int]) -> Dict[int,int]:\n",
    "    \"\"\"\n",
    "    Greedy matching: assign each target to closest available elevator.\n",
    "    Returns: elevator_id -> target_floor\n",
    "    \"\"\"\n",
    "    eids = list(elevator_floors.keys())\n",
    "    remaining = set(eids)\n",
    "    assignment = {}\n",
    "\n",
    "    for tgt in targets:\n",
    "        best_e, best_d = None, None\n",
    "        for e in list(remaining):\n",
    "            d = abs(elevator_floors[e] - tgt)\n",
    "            if best_d is None or d < best_d:\n",
    "                best_d = d\n",
    "                best_e = e\n",
    "        if best_e is None:\n",
    "            break\n",
    "        assignment[best_e] = tgt\n",
    "        remaining.remove(best_e)\n",
    "\n",
    "    # Any leftover elevators (if more idle than targets): keep them where they are\n",
    "    for e in remaining:\n",
    "        assignment[e] = elevator_floors[e]\n",
    "    return assignment\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Lightweight event simulator for waiting time\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class ElevatorState:\n",
    "    floor: int\n",
    "    available_time: pd.Timestamp  # when elevator can take new call\n",
    "\n",
    "def travel_time_seconds(f1: int, f2: int) -> float:\n",
    "    return abs(int(f1) - int(f2)) * SECONDS_PER_FLOOR\n",
    "\n",
    "def infer_initial_positions(stop: pd.DataFrame, start_time: pd.Timestamp) -> Dict[int,int]:\n",
    "    \"\"\"\n",
    "    Infer elevator last known floor before start_time from car_stops.\n",
    "    Falls back to lobby if unknown.\n",
    "    \"\"\"\n",
    "    eid_col = pick_col(stop, [\"Elevator\",\"elevator\",\"CarID\",\"CarId\",\"LiftID\",\"ID\"], required=False)\n",
    "    floor_col = pick_col(stop, [\"Floor\",\"floor\",\"StopFloor\",\"AtFloor\",\"CurrentFloor\"], required=False)\n",
    "\n",
    "    pos = {i: LOBBY_FLOOR for i in range(N_ELEVATORS)}\n",
    "    if eid_col is None or floor_col is None:\n",
    "        return pos\n",
    "\n",
    "    s = stop[stop[\"Time\"] <= start_time].copy()\n",
    "    if s.empty:\n",
    "        return pos\n",
    "\n",
    "    s = s.sort_values(\"Time\")\n",
    "    last = s.groupby(eid_col).tail(1)\n",
    "    for _, r in last.iterrows():\n",
    "        try:\n",
    "            eid = int(r[eid_col])\n",
    "            pos[eid] = int(r[floor_col])\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pos\n",
    "\n",
    "def simulate(strategy: str,\n",
    "             hall: pd.DataFrame,\n",
    "             feats: pd.DataFrame,\n",
    "             mode_pipe: Pipeline,\n",
    "             mode_features: List[str],\n",
    "             cluster_to_label: Dict[int,str],\n",
    "             demand_by_cluster_floor: pd.DataFrame,\n",
    "             start_time: Optional[pd.Timestamp]=None,\n",
    "             end_time: Optional[pd.Timestamp]=None) -> Dict[str,float]:\n",
    "    \"\"\"\n",
    "    strategy in {\"last_stop\",\"lobby\",\"dynamic\"}.\n",
    "    \"\"\"\n",
    "    # columns\n",
    "    h_floor = pick_col(hall, [\"Floor\",\"floor\",\"OriginFloor\",\"FromFloor\",\"HallFloor\",\"StartFloor\"], required=True)\n",
    "\n",
    "    hall = hall.sort_values(\"Time\").copy()\n",
    "    if start_time is None:\n",
    "        start_time = hall[\"Time\"].min()\n",
    "    if end_time is None:\n",
    "        end_time = hall[\"Time\"].max()\n",
    "\n",
    "    # Filter simulation interval\n",
    "    hall_sim = hall[(hall[\"Time\"] >= start_time) & (hall[\"Time\"] <= end_time)].copy()\n",
    "    if hall_sim.empty:\n",
    "        return {\"AWT\": np.nan, \"LongWaitPct\": np.nan, \"N\": 0}\n",
    "\n",
    "    # Initial elevator states\n",
    "    # (use last stop before start_time if possible; otherwise lobby)\n",
    "    _, stop, _, _, _ = load_data()\n",
    "    init_pos = infer_initial_positions(stop, start_time)\n",
    "\n",
    "    elevators = {\n",
    "        e: ElevatorState(floor=init_pos.get(e, LOBBY_FLOOR), available_time=start_time)\n",
    "        for e in range(N_ELEVATORS)\n",
    "    }\n",
    "\n",
    "    # Precompute demand lookup: (cluster -> arrays floors, weights)\n",
    "    demand_group = demand_by_cluster_floor.groupby(\"cluster\")\n",
    "    demand_lookup = {}\n",
    "    for cl, dfc in demand_group:\n",
    "        floors = dfc[\"floor\"].astype(int).values\n",
    "        w = dfc[\"cnt\"].astype(float).values\n",
    "        # avoid all-zero\n",
    "        if w.sum() <= 0:\n",
    "            w = np.ones_like(w)\n",
    "        demand_lookup[int(cl)] = (floors, w)\n",
    "\n",
    "    waits = []\n",
    "\n",
    "    # Decision times for parking\n",
    "    decision_times = pd.date_range(start=start_time.floor(DECISION_FREQ),\n",
    "                                   end=end_time.ceil(DECISION_FREQ),\n",
    "                                   freq=DECISION_FREQ)\n",
    "\n",
    "    # Helper to get cluster at a decision time (nearest available feature row)\n",
    "    feats_idx = feats.set_index(\"Time\").sort_index()\n",
    "\n",
    "    def get_cluster_label_at(t: pd.Timestamp) -> Tuple[int,str]:\n",
    "        # use exact row if exists, else previous\n",
    "        tt = t.floor(DECISION_FREQ)\n",
    "        if tt in feats_idx.index:\n",
    "            row = feats_idx.loc[tt]\n",
    "        else:\n",
    "            # previous available\n",
    "            row = feats_idx.loc[:tt].tail(1)\n",
    "            if isinstance(row, pd.DataFrame):\n",
    "                row = row.iloc[0]\n",
    "        X = row[mode_features].fillna(0.0).values.reshape(1, -1)\n",
    "        cl = int(mode_pipe.predict(X)[0])\n",
    "        return cl, cluster_to_label.get(cl, \"Unknown\")\n",
    "\n",
    "    # Parking policy invoked at decision times\n",
    "    def apply_parking_policy(t: pd.Timestamp):\n",
    "        # Identify idle elevators (available_time <= t)\n",
    "        idle = [e for e, st in elevators.items() if st.available_time <= t]\n",
    "\n",
    "        if len(idle) == 0:\n",
    "            return\n",
    "\n",
    "        if strategy == \"last_stop\":\n",
    "            return\n",
    "\n",
    "        if strategy == \"lobby\":\n",
    "            for e in idle:\n",
    "                st = elevators[e]\n",
    "                if st.floor != LOBBY_FLOOR:\n",
    "                    tt = travel_time_seconds(st.floor, LOBBY_FLOOR)\n",
    "                    st.available_time = t + pd.Timedelta(seconds=tt)\n",
    "                    st.floor = LOBBY_FLOOR\n",
    "            return\n",
    "\n",
    "        if strategy == \"dynamic\":\n",
    "            cl, _ = get_cluster_label_at(t)\n",
    "\n",
    "            # demand for next horizon: scale weights by horizon slices\n",
    "            if cl in demand_lookup:\n",
    "                floors, w = demand_lookup[cl]\n",
    "            else:\n",
    "                # fallback to global\n",
    "                allf = demand_by_cluster_floor.groupby(\"floor\")[\"cnt\"].mean().reset_index()\n",
    "                floors = allf[\"floor\"].astype(int).values\n",
    "                w = allf[\"cnt\"].astype(float).values\n",
    "                if w.sum() <= 0:\n",
    "                    w = np.ones_like(w)\n",
    "\n",
    "            # Choose k target parking floors for number of idle elevators\n",
    "            k = min(len(idle), N_ELEVATORS)\n",
    "            # Reduce to unique floors if too many\n",
    "            if len(floors) == 0:\n",
    "                targets = [LOBBY_FLOOR] * k\n",
    "            else:\n",
    "                # If floors extremely many, keep top by weight to stabilize DP\n",
    "                if len(floors) > 60:\n",
    "                    top_idx = np.argsort(-w)[:60]\n",
    "                    floors2, w2 = floors[top_idx], w[top_idx]\n",
    "                else:\n",
    "                    floors2, w2 = floors, w\n",
    "\n",
    "                # normalize weights\n",
    "                w2 = w2 / (w2.sum() + 1e-12)\n",
    "\n",
    "                # Compute k-median targets\n",
    "                targets = weighted_k_median_1d(floors2, w2, k)\n",
    "\n",
    "            # Assign idle elevators to targets\n",
    "            cur_pos = {e: elevators[e].floor for e in idle}\n",
    "            assignment = assign_elevators_to_targets(cur_pos, targets)\n",
    "\n",
    "            for e, tgt in assignment.items():\n",
    "                st = elevators[e]\n",
    "                if st.floor != tgt:\n",
    "                    tt = travel_time_seconds(st.floor, tgt)\n",
    "                    st.available_time = t + pd.Timedelta(seconds=tt)\n",
    "                    st.floor = tgt\n",
    "\n",
    "    # Simulation loop over calls; we also apply parking at decision points\n",
    "    decision_ptr = 0\n",
    "    decision_times = list(decision_times)\n",
    "\n",
    "    for _, call in hall_sim.iterrows():\n",
    "        call_time = call[\"Time\"]\n",
    "        origin_floor = int(call[h_floor])\n",
    "\n",
    "        # Apply parking decisions up to this call_time\n",
    "        while decision_ptr < len(decision_times) and decision_times[decision_ptr] <= call_time:\n",
    "            apply_parking_policy(decision_times[decision_ptr])\n",
    "            decision_ptr += 1\n",
    "\n",
    "        # Choose an elevator to serve this call:\n",
    "        # minimize arrival time = max(available_time, call_time) + travel_time(current_floor -> origin)\n",
    "        best_e = None\n",
    "        best_arrival = None\n",
    "\n",
    "        for e, st in elevators.items():\n",
    "            start_service = max(st.available_time, call_time)\n",
    "            arr = start_service + pd.Timedelta(seconds=travel_time_seconds(st.floor, origin_floor))\n",
    "            if best_arrival is None or arr < best_arrival:\n",
    "                best_arrival = arr\n",
    "                best_e = e\n",
    "\n",
    "        # Waiting time: arrival - call_time (doors open assumed at arrival + DOOR_TIME doesn't affect waiting-to-arrival)\n",
    "        wait_sec = (best_arrival - call_time).total_seconds()\n",
    "        waits.append(wait_sec)\n",
    "\n",
    "        # Update chosen elevator state: after serving, elevator stays at origin floor, becomes available after door time\n",
    "        st = elevators[best_e]\n",
    "        st.floor = origin_floor\n",
    "        st.available_time = best_arrival + pd.Timedelta(seconds=DOOR_TIME)\n",
    "\n",
    "    waits = np.array(waits, dtype=float)\n",
    "    awt = float(np.mean(waits)) if len(waits) else np.nan\n",
    "    long_pct = float(np.mean(waits >= LONG_WAIT_THRESHOLD) * 100.0) if len(waits) else np.nan\n",
    "\n",
    "    return {\"AWT\": awt, \"LongWaitPct\": long_pct, \"N\": int(len(waits))}\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Train everything + run comparison\n",
    "# -----------------------------\n",
    "def run_task3_demo():\n",
    "    hall, _, _, _, _ = load_data()\n",
    "\n",
    "    # (A) Build mode features + cluster model\n",
    "    feats = build_5min_features()\n",
    "    mode_pipe, mode_features, feats_clustered = train_mode_cluster(feats, n_clusters=N_CLUSTERS)\n",
    "    cl_to_label = label_clusters(feats_clustered)\n",
    "\n",
    "    # (B) Learn demand by (cluster, floor)\n",
    "    demand = learn_floor_demand_by_mode(hall, feats_clustered)\n",
    "\n",
    "    # (C) Choose a simulation window (e.g., last 3 days) to keep runtime reasonable\n",
    "    # You can expand to full 30 days once happy.\n",
    "    tmin = hall[\"Time\"].min()\n",
    "    tmax = hall[\"Time\"].max()\n",
    "    sim_start = max(tmin, tmax - pd.Timedelta(days=3))\n",
    "    sim_end = tmax\n",
    "\n",
    "    # (D) Evaluate strategies\n",
    "    results = {}\n",
    "    for strat in [\"last_stop\", \"lobby\", \"dynamic\"]:\n",
    "        res = simulate(\n",
    "            strategy=strat,\n",
    "            hall=hall,\n",
    "            feats=feats_clustered,\n",
    "            mode_pipe=mode_pipe,\n",
    "            mode_features=mode_features,\n",
    "            cluster_to_label=cl_to_label,\n",
    "            demand_by_cluster_floor=demand,\n",
    "            start_time=sim_start,\n",
    "            end_time=sim_end\n",
    "        )\n",
    "        results[strat] = res\n",
    "\n",
    "    print(\"\\n========== Task3 Strategy Comparison ==========\")\n",
    "    print(f\"Simulation window: {sim_start}  ->  {sim_end}\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"{k:>10} | AWT={v['AWT']:.2f}s | LongWait%={v['LongWaitPct']:.2f}% | N={v['N']}\")\n",
    "\n",
    "    # Save artifacts useful for report\n",
    "    feats_clustered.to_csv(str(OUT_DATA / \"task3_mode_features_5min.csv\"), index=False)\n",
    "\n",
    "\n",
    "    # --- Export Task2 mode timeline (Time, cluster, mode_label) ---\n",
    "    feats_clustered = feats_clustered.copy()\n",
    "    feats_clustered[\"mode_label\"] = feats_clustered[\"cluster\"].map(cl_to_label)\n",
    "    timeline = feats_clustered[[\"Time\",\"cluster\",\"mode_label\"]].copy()\n",
    "    timeline.to_csv(str(OUT_DATA / \"task2_modes_timeline.csv\"), index=False)\n",
    "    print(f\"Saved mode timeline to: {str(OUT_DATA / 'task2_modes_timeline.csv')}\")\n",
    "\n",
    "    # --- Export Task3 demand weights by (cluster, floor) ---\n",
    "    # learn_floor_demand_by_mode returns columns: cluster, floor, cnt (avg calls per slice)\n",
    "    demand_out = demand.copy()\n",
    "    if \"floor\" in demand_out.columns:\n",
    "        demand_out = demand_out.rename(columns={\"floor\":\"Floor\"})\n",
    "    if \"cnt\" in demand_out.columns:\n",
    "        demand_out = demand_out.rename(columns={\"cnt\":\"count\"})\n",
    "    if \"count\" in demand_out.columns:\n",
    "        demand_out[\"weight\"] = demand_out[\"count\"] / demand_out.groupby(\"cluster\")[\"count\"].transform(\"sum\")\n",
    "    demand_out[[\"cluster\",\"Floor\",\"weight\"]].to_csv(str(OUT_DATA / \"task3_demand_cluster_floor.csv\"), index=False)\n",
    "    print(f\"Saved cluster-floor demand weights to: {str(OUT_DATA / 'task3_demand_cluster_floor.csv')}\")\n",
    "\n",
    "\n",
    "    \n",
    "    # Save simulation summary for report tables\n",
    "    try:\n",
    "        sim_rows = []\n",
    "        for strat, v in results.items():\n",
    "            sim_rows.append({\n",
    "                \"strategy\": strat,\n",
    "                \"AWT_sec\": float(v.get(\"AWT\", np.nan)),\n",
    "                \"LongWait_pct\": float(v.get(\"LongWaitPct\", np.nan)),\n",
    "                \"N_calls\": int(v.get(\"N\", 0))\n",
    "            })\n",
    "        sim_df = pd.DataFrame(sim_rows)\n",
    "        sim_out = str(OUT_DATA / \"task3_sim_results.csv\")\n",
    "        sim_df.to_csv(sim_out, index=False)\n",
    "        print(f\"Saved simulation summary to: {sim_out}\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Task3 sim export failed:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_task3_demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "047ada75-bc5a-43be-a7ea-c1a3d789342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1_pred_series.csv OK shape= (1293, 3) cols= ['Time', 'y_true', 'y_pred']\n",
      "task2_modes_timeline.csv MISSING\n",
      "task3_mode_features_5min.csv MISSING\n",
      "task3_demand_cluster_floor.csv MISSING\n",
      "task3_sim_results.csv MISSING\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files = [\n",
    "    OUT_DATA / \"task1_pred_series.csv\",\n",
    "    OUT_DATA / \"task2_modes_timeline.csv\",\n",
    "    OUT_DATA / \"task3_mode_features_5min.csv\",\n",
    "    OUT_DATA / \"task3_demand_cluster_floor.csv\",\n",
    "    OUT_DATA / \"task3_sim_results.csv\",\n",
    "]\n",
    "\n",
    "for p in files:\n",
    "    if p.exists():\n",
    "        df = pd.read_csv(p)\n",
    "        print(p.name, \"OK\", \"shape=\", df.shape, \"cols=\", df.columns.tolist()[:10])\n",
    "    else:\n",
    "        print(p.name, \"MISSING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db412cb-328a-4c3e-b7c4-43f452598697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}